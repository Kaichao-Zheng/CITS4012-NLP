{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "# 2025 CITS4012 Group 9 Assignment\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Kaichao-Zheng/CITS4012-NLP/blob/main/CITS4012_Group9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOsq3No1kRC-"
   },
   "source": [
    "# Collaborators\n",
    "\n",
    "| Uni ID   | Student Name  | GitHub Username                                   |\n",
    "| -------- | ------------- | ------------------------------------------------- |\n",
    "| 24141207 | Kaichao Zheng | [Kaichao-Zheng](https://github.com/Kaichao-Zheng) |\n",
    "| 24645175 | Ziqi Meng     | [jiongge39](https://github.com/jiongge39)         |\n",
    "| 23998001 | Yanglei Yuan  | [LeoYuan0225](https://github.com/LeoYuan0225)     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LPgCx5t-0f8"
   },
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTV2-AYuV_lx"
   },
   "source": [
    "> NOTE:\n",
    ">\n",
    "> In Google Colab, an ERROR would occur due to incompatibility of the latest versions of `numpy` and `scipy`.\n",
    ">\n",
    "> Simply **restart the runtime** to use the newly downgraded versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XsKNGCKj_DxD",
    "outputId": "63b72ccc-6e96-4210-b760-0e016a39cbfc"
   },
   "outputs": [],
   "source": [
    "%pip install word2number\n",
    "%pip install contractions\n",
    "%pip install nltk\n",
    "%pip install pandas\n",
    "%pip install gensim\n",
    "%pip install matplotlib\n",
    "%pip install wordcloud\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0at-kJs67gh"
   },
   "source": [
    "# 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcBQf2U37lwG"
   },
   "source": [
    "We implemented three different model architectures:\n",
    "\n",
    "* [The Vanilla Bi-LSTM NLI Classifier](#scrollTo=67TQJgOJ_lF1)\n",
    "\n",
    "* [Bi-LSTM + Attention NLI Classifier](#scrollTo=BhSE5ON4_r0C)\n",
    "\n",
    "* [Model 3](#scrollTo=E4w_n2P2_xxm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tgj4JarkjAY"
   },
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eylhXsB4Fb_V"
   },
   "source": [
    "## 2.1 Load JSON files from GitHub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZlBU0GAUiTD",
    "outputId": "23fa0dcf-a6b3-4508-ccf6-2e970913a821"
   },
   "outputs": [],
   "source": [
    "# Define JSON dataset paths\n",
    "base_url = \"https://raw.githubusercontent.com/Kaichao-Zheng/CITS4012-NLP/main/\"\n",
    "\n",
    "train_file = base_url + \"train.json\"\n",
    "val_file = base_url + \"validation.json\"\n",
    "test_file = base_url + \"test.json\"\n",
    "\n",
    "# Quick check\n",
    "print(\"âœ… Dataset URLs:\")\n",
    "print(\"Train:\\t\", train_file)\n",
    "print(\"Val:\\t\", val_file)\n",
    "print(\"Test:\\t\", test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vF0lwUqfkj6p",
    "outputId": "596b3466-0657-49a3-9520-d89ccaef9114"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Working dataframes\n",
    "train_df = pd.read_json(train_file)\n",
    "val_df = pd.read_json(val_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "\n",
    "# Keep original copies\n",
    "source_train_df = train_df.copy()\n",
    "source_val_df = val_df.copy()\n",
    "source_test_df = test_df.copy()\n",
    "\n",
    "# Sneak peek\n",
    "pd.set_option(\"display.max_colwidth\", 30)\n",
    "\n",
    "print(train_df.head())\n",
    "# print(val_df.head())\n",
    "# print(test_df.head())\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Val size:\", len(val_df))\n",
    "print(\"Test size:\", len(test_df))\n",
    "\n",
    "pd.reset_option(\"display.max_colwidth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJZtrMRPnYld"
   },
   "source": [
    "## 2.2 Define difference viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7PZFNNUncY7"
   },
   "outputs": [],
   "source": [
    "import html\n",
    "from difflib import SequenceMatcher\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def verify_print(source_df, cleaned_df, tag, num, col, idx_src ,idx_now, kept=False):\n",
    "  status = \"Kept \" if kept else \"Reindexed\"\n",
    "  print(f\"{tag} {num}:\\tidx_src: {idx_src}\\t{source_df[col][idx_src]}\")\n",
    "  print(f\"{status} {num}:\\tidx_now: {idx_now}\\t{cleaned_df[col][idx_now]}\")\n",
    "  print()\n",
    "\n",
    "# You can enable dark mode by replacing default \"light\" here\n",
    "def verify_diff(source_df, cleaned_df, tag, num, col, index, kept=False, theme=\"dark\"):\n",
    "  if theme == \"light\":\n",
    "    bg = \"#fafafa\"; fg = \"#000000\"\n",
    "    del_bg = \"#ffdddd\"; ins_bg = \"#ddffdd\"\n",
    "    del_fg = \"#aa0000\"; ins_fg = \"#006600\"\n",
    "  else:\n",
    "    bg = \"#1e1e1e\"; fg = \"#e0e0e0\"\n",
    "    del_bg = \"#662222\"; ins_bg = \"#224422\"\n",
    "    del_fg = \"#ff9999\"; ins_fg = \"#99ff99\"\n",
    "\n",
    "  status = \"Kept\" if kept else \"Fixed\"\n",
    "\n",
    "  original = source_df[col][index]\n",
    "  cleaned = cleaned_df[col][index]\n",
    "\n",
    "  matcher = SequenceMatcher(None, original, cleaned)\n",
    "\n",
    "  html_original = f\"\"\"\n",
    "  <div style='margin-bottom: 10px; background-color:{bg}; color:{fg}; white-space: nowrap; font-family: monospace; padding: 5px; border-radius:4px;'>\n",
    "  <b>{tag} {num}:</b> \"\"\"\n",
    "  html_cleaned = f\"\"\"\n",
    "  <div style='margin-bottom: 10px; background-color:{bg}; color:{fg}; white-space: nowrap; font-family: monospace; padding: 5px; border-radius:4px;'>\n",
    "  <b>{status} {num}:</b> \"\"\"\n",
    "\n",
    "  for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
    "    orig_text = original[i1:i2].replace(\" \", \"&nbsp;\")\n",
    "    clean_text = cleaned[j1:j2].replace(\" \", \"&nbsp;\")\n",
    "\n",
    "    if tag == 'equal':\n",
    "      html_original += orig_text\n",
    "      html_cleaned += clean_text\n",
    "    elif tag == 'delete':\n",
    "      html_original += f\"<span style='background-color:{del_bg}; color:{del_fg};'>{orig_text}</span>\"\n",
    "    elif tag == 'insert':\n",
    "      html_cleaned += f\"<span style='background-color:{ins_bg}; color:{ins_fg};'>{clean_text}</span>\"\n",
    "    elif tag == 'replace':\n",
    "      html_original += f\"<span style='background-color:{del_bg}; color:{del_fg};'>{orig_text}</span>\"\n",
    "      html_cleaned += f\"<span style='background-color:{ins_bg}; color:{ins_fg};'>{clean_text}</span>\"\n",
    "\n",
    "  html_original += \"</div>\"\n",
    "  html_cleaned += \"</div>\"\n",
    "\n",
    "  display(HTML(html_original + html_cleaned + \"<hr/>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9ibjBESaH08"
   },
   "source": [
    "## 2.3 Data cleansing\n",
    "\n",
    "In principle, the data cleansing rules are derived solely from the training set to prevent information leakage.\n",
    "\n",
    "This design intentionally preserves out-of-vocabulary (OOV) cases in the validation and test sets, which are represented by \\<UNK> tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzfrlfEJgpZ_"
   },
   "source": [
    "Assumption\n",
    "* The value of `label` is binary, either \"neutral\" or \"entails\".\n",
    "\n",
    "Compromises\n",
    "* Ignore syntactic errors and semantic errors.\n",
    "* Apply unified premises rules on hypothesis.\n",
    "\n",
    "Handled Issues\n",
    "| No. | Description | Examples |\n",
    "|----------|-------------|-----------|\n",
    "| Issue 1 | HTML/XML tags with ID pattern | train premise 78, 270, 319, ... |\n",
    "| Issue 2 | Non-linguistic long/pure separators | train premise 1, 382, 385, ... |\n",
    "| Issue 3 | Duplicate consecutive phrases | train premise 78, 87, 564, ... |\n",
    "| Issue 4 | Single-word sentences  | train premise 146, 181, 427, ... |\n",
    "| Issue 5 | Duplicated whitespaces | train premise 123, 193, 259, ... |\n",
    "| Issue 6 | Spaces before punctuations, except '!' and '?' | train premise 3, 333, 6280 |\n",
    "| Issue 7 | Premise with long concatenated sentences | train premise 270, 537, 608, ... |\n",
    "\n",
    "Kept Noises\n",
    "\n",
    "| No. | Description | Noise | Non-Noise |\n",
    "|----------|-------------|----------|--------------|\n",
    "| Noise 1 | Instructional prompt words | train premise 3, 61, 319, ... | train premise 16, 24, 61, ... |\n",
    "| Noise 2 | Numbered markers | train premise 270, 537, 608, ... | train premise 1546, 2068, ... |\n",
    "| Noise 3 | Misplaced `label` values | train premise 270, 537, 606, ... | train premise 1683, 2068, ... |\n",
    "| Noise 4 | Metadata prefixes | train premise 32, 230, 482, ... |  |\n",
    "| Noise 5 | Isolated single symbols | train premise 60, 1185 | comparison operators |\n",
    "\n",
    "\n",
    "Limitation\n",
    "\n",
    "The difference viewer automatically escapes HTML entities, which might overlook HTML noise. (E.g., &amp;quot; in train premise 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "id": "w1jUqkRJadr_",
    "outputId": "a8109706-ecb4-417a-9ccb-f86635137482"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanse(df):\n",
    "  df = df.copy()\n",
    "\n",
    "  ID_PATTERN = r\"\\b[A-Za-z]?(?:\\d{6,}|[A-Za-z0-9]{8,})(?:-[A-Za-z0-9]{2,})+\\b\"\n",
    "  REPEAT_PATTERN = r\"\\b((?:\\w+\\s+){0,2}\\w+)( \\1\\b)+\"\n",
    "\n",
    "  for col in [\"premise\", \"hypothesis\"]:\n",
    "\n",
    "    # pre-trim: two-tailed whitespaces\n",
    "    df[col] = df[col].apply(lambda x: x.strip())\n",
    "\n",
    "    # issue 1: HTML/XML tags with ID pattern\n",
    "    df[col] = df[col].apply(html.unescape)\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r\"<[^>]*>\", \" \", x))\n",
    "    df[col] = df[col].apply(lambda x: re.sub(ID_PATTERN, \" \", x))\n",
    "\n",
    "    # issue 2: non-linguistic long/pure separators\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r\"[-=*_~$]{3,}\", \" \", x))\n",
    "    df[col] = df[col].apply(lambda x: \"\" if re.fullmatch(r\"[\\W_]+\", x.strip()) else x)\n",
    "\n",
    "    # issue 3: duplicate consecutive phrases\n",
    "    df[col] = df[col].apply(lambda x: re.sub(REPEAT_PATTERN, r\"\\1\", x))\n",
    "\n",
    "    # issue 4: single-word sentences\n",
    "    df[col] = df[col].apply(lambda x: \"\" if re.fullmatch(r\"(\\w+[.!?']?|[^\\w\\s]+)\", x.strip()) else x)\n",
    "\n",
    "    # issue 5: duplicate whitespaces\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r\"\\s+\", \" \", x).strip())\n",
    "\n",
    "    # issue 6: spaces before punctuations\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r\"\\s+([.,;:])\", r\"\\1\", x))\n",
    "\n",
    "  return df\n",
    "\n",
    "# Clenasing\n",
    "train_df = cleanse(train_df)\n",
    "val_df = cleanse(val_df)\n",
    "test_df = cleanse(test_df)\n",
    "\n",
    "# Keep cleaned copies\n",
    "cleaned_train_df = train_df.copy()\n",
    "cleaned_val_df = val_df.copy()\n",
    "cleaned_test_df = test_df.copy()\n",
    "\n",
    "# Verification\n",
    "verify_diff(source_train_df, cleaned_train_df, tag=\"Issue\", num=1, col=\"premise\", index=319)\n",
    "verify_diff(source_train_df, cleaned_train_df, tag=\"Issue\", num=2, col=\"premise\", index=1)\n",
    "verify_diff(source_train_df, cleaned_train_df, tag=\"Issue\", num=3, col=\"premise\", index=87)\n",
    "verify_diff(source_train_df, cleaned_train_df, tag=\"Issue\", num=4, col=\"premise\", index=146)\n",
    "verify_diff(source_train_df, cleaned_train_df, tag=\"Issue\", num=5, col=\"premise\", index=123)\n",
    "verify_diff(source_train_df, cleaned_train_df, tag=\"Issue\", num=6, col=\"premise\", index=3)\n",
    "# verify_diff(source_train_df, cleaned_train_df, tag=\"Issue\", num=6, col=\"premise\", index=6280, kept=True)  # why except '?'\n",
    "# verify_diff(source_train_df, cleaned_train_df, tag=\"Issue\", num=6, col=\"premise\", index=333, kept=True)  # why except '!'\n",
    "verify_diff(source_train_df, cleaned_train_df, tag=\"Issue\", num=\"Hybrid\", col=\"premise\", index=270)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDOTLdmDKwfy"
   },
   "source": [
    "## 2.4 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rc0V-G-Ei8lr",
    "outputId": "54180d49-c671-4eec-bc45-b09d50afea20"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "sww = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "gAEbhAKoKyEW",
    "outputId": "3f871f8e-8bb8-47f6-9a4e-6764f555721b"
   },
   "outputs": [],
   "source": [
    "import re, contractions\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from word2number import w2n\n",
    "from contractions import fix as expand_contractions\n",
    "\n",
    "def word2num(text):\n",
    "  def convert(match):\n",
    "    word = match.group(0)\n",
    "    try:\n",
    "      return f\" {w2n.word_to_num(word)} \"\n",
    "    except:\n",
    "      return f\" {word} \"\n",
    "  text = re.sub(\n",
    "    r'\\b(?:zero|one|two|three|four|five|six|seven|eight|nine|ten|'\n",
    "    r'eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|'\n",
    "    r'eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|'\n",
    "    r'eighty|ninety|hundred|thousand|million|billion|and|[- ])+\\b',\n",
    "    convert, text)\n",
    "  return ' '.join(text.split())\n",
    "\n",
    "def normalize(df):\n",
    "  df = df.copy()\n",
    "\n",
    "  for col in [\"premise\", \"hypothesis\"]:\n",
    "\n",
    "    # rule 1: lowercase\n",
    "    df[col] = df[col].str.lower()\n",
    "\n",
    "    # rule 2: expand contraction\n",
    "    df[col] = df[col].apply(expand_contractions)\n",
    "\n",
    "    # rule -1: remove stopwords\n",
    "    # df[col] = df[col].apply(lambda x: \" \".join([w for w in word_tokenize(x) if w.lower() not in sww]))\n",
    "\n",
    "    # rule -2: remove bracketed content\n",
    "    # df[col] = df[col].apply(lambda x: re.sub(r'\\([^)]*\\)', '', x))\n",
    "\n",
    "    # rule -3: symbolize linguistic numbers\n",
    "    # df[col] = df[col].apply(word2num)\n",
    "\n",
    "  return df\n",
    "\n",
    "# Normalization\n",
    "train_df = normalize(train_df)\n",
    "val_df = normalize(val_df)\n",
    "test_df = normalize(test_df)\n",
    "\n",
    "# Keep normalized copies\n",
    "normalized_train_df = train_df.copy()\n",
    "normalized_val_df = val_df.copy()\n",
    "normalized_test_df = test_df.copy()\n",
    "\n",
    "# Verification\n",
    "verify_diff(cleaned_train_df, normalized_train_df, tag=\"Rule\", num=\"1\", col=\"premise\", index=1)\n",
    "verify_diff(cleaned_train_df, normalized_train_df, tag=\"Rule\", num=\"2\", col=\"premise\", index=420)\n",
    "verify_diff(cleaned_train_df, normalized_train_df, tag=\"Rule\", num=\"2\", col=\"hypothesis\", index=8, kept=True)\n",
    "\n",
    "# Inactivate rules\n",
    "# verify_diff(cleaned_train_df, normalized_train_df, tag=\"Rule\", num=-1, col=\"premise\", index=1, kept=True)\n",
    "# verify_diff(cleaned_train_df, normalized_train_df, tag=\"Rule\", num=-2, col=\"premise\", index=8, kept=True)\n",
    "# verify_diff(cleaned_train_df, normalized_train_df, tag=\"Rule\", num=-3, col=\"premise\", index=147, kept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1j8PKb8i3zP"
   },
   "source": [
    "## 2.5 Reindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzpo8vldi509",
    "outputId": "5b7f7469-d2d3-4e27-8829-eee441bcbec8"
   },
   "outputs": [],
   "source": [
    "def reindex(df):\n",
    "  df = df.copy()\n",
    "\n",
    "  for col in [\"premise\", \"hypothesis\"]:\n",
    "\n",
    "    # post-issue 4: remove rows with empty cell\n",
    "    df = df[df[col].astype(str).str.strip() != \"\"]\n",
    "\n",
    "  # issue 7: premise with long concatenated sentences\n",
    "  new_rows = []\n",
    "  for _, row in df.iterrows():\n",
    "    premise = str(row[\"premise\"]).strip()\n",
    "    hypothesis = str(row[\"hypothesis\"]).strip()\n",
    "    label = str(row[\"label\"]).strip()\n",
    "\n",
    "    if not premise:\n",
    "      continue\n",
    "\n",
    "    # split by \". \" or \"; \" to avoid 3.14\n",
    "    sentences = re.split(r'(?<!\\d)(?<=[.;])\\s+(?=[A-Za-z])', premise)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "    for s in sentences:\n",
    "      new_rows.append({\n",
    "        \"premise\": s,\n",
    "        \"hypothesis\": hypothesis,\n",
    "        \"label\": label\n",
    "      })\n",
    "  df = pd.DataFrame(new_rows)\n",
    "\n",
    "  # reorder index\n",
    "  df = df.reset_index(drop=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "# Reindexing\n",
    "train_df = reindex(train_df)\n",
    "val_df = reindex(val_df)\n",
    "test_df = reindex(test_df)\n",
    "\n",
    "# Keep reindexed copies\n",
    "reindexed_train_df = train_df.copy()\n",
    "reindexed_val_df = val_df.copy()\n",
    "reindexed_test_df = test_df.copy()\n",
    "\n",
    "# Verification\n",
    "verify_print(normalized_train_df, reindexed_train_df, tag=\"Post-Issue\", num=4, col=\"premise\", idx_src=147, idx_now=158)\n",
    "verify_print(normalized_train_df, reindexed_train_df, tag=\"Issue\", num=7, col=\"premise\", idx_src=31, idx_now=31, kept=True)\n",
    "verify_print(normalized_train_df, reindexed_train_df, tag=\"Issue\", num=7, col=\"premise\", idx_src=270, idx_now=281)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adtX9t6XKyTd"
   },
   "source": [
    "## 2.6 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mX8ghj_AK0uG",
    "outputId": "9b570374-25d7-43fd-d5fc-36f4564b9680"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "ZVPHolC0DPzA",
    "outputId": "24b266b1-ba23-48e6-9879-4a4a6f33b116"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def protect_float(text: str) -> str:\n",
    "  return re.sub(r\"(?<=\\d)\\.(?=\\d)\", \"DOTTK\", text)\n",
    "\n",
    "def recover_float(tokens):\n",
    "  return [t.replace(\"DOTTK\", \".\") for t in tokens]\n",
    "\n",
    "def tokenize(df):\n",
    "  df = df.copy()\n",
    "  KEEP_SYMBOLS = set(\"=<>+-/*%!\")\n",
    "\n",
    "  for col in [\"premise\", \"hypothesis\"]:\n",
    "    # Remove punctuations\n",
    "    df[col] = df[col].apply(lambda x: protect_float(x))\n",
    "    df[col] = df[col].apply(lambda x: [t for t in word_tokenize(x) if t not in string.punctuation or t in KEEP_SYMBOLS])\n",
    "    df[col] = df[col].apply(lambda toks: recover_float(toks))\n",
    "\n",
    "  return df\n",
    "\n",
    "# Tokenization\n",
    "tokenized_train_df = tokenize(train_df)\n",
    "tokenized_val_df = tokenize(val_df)\n",
    "tokenized_test_df = tokenize(test_df)\n",
    "\n",
    "# Quick check\n",
    "preview_rows = pd.concat([\n",
    "  tokenized_train_df.head(),\n",
    "  tokenized_train_df.iloc[[6, 23, 34, 62, 369, 438, 2116]]  # concatenate indeces 6, 23, 32, 60, 319, 385, 1185\n",
    "])\n",
    "\n",
    "display(preview_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nm9wewk0QTzH"
   },
   "source": [
    "## 2.7 Visualisation via Word Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b48-JUWxRG28"
   },
   "source": [
    "We actually include stopwords in the tokenized dataframes for model training,\n",
    "\n",
    "but temporarily remove them here for visualisation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "0robldKbRWOK",
    "outputId": "21787cca-2e92-4643-e010-45f35daabb12"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "sww = stopwords.words('english')\n",
    "\n",
    "for col in [\"premise\", \"hypothesis\"]:\n",
    "  tokens = []\n",
    "  # Remove punctuation, number, and stopword tokens temporarily\n",
    "  for toks in tokenized_train_df[col]:\n",
    "    tokens.extend([t.lower() for t in toks if t.isalpha() and t.lower() not in sww])\n",
    "  wordcloud = WordCloud(background_color=\"white\").generate(\" \".join(tokens))\n",
    "  plt.figure()\n",
    "  plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "  plt.axis(\"off\")\n",
    "  plt.title(f\"{col.capitalize()} Word Cloud (Train Set)\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDxZSK20klWr"
   },
   "source": [
    "# 3. Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoSbUcLGaURF"
   },
   "source": [
    "## 3.1 Token vocabulary\n",
    "\n",
    "The vocabulary only includes tokens in train set with `frequency >= 3`.\n",
    "\n",
    "Therefore, a token with low frequency will be regarded as \\<UNK>.\n",
    "\n",
    "E.g. the token \"6.39\" from the first premise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i6MnwSgIVx58",
    "outputId": "861fb70d-4b42-4771-b55c-76a4e40cff6e"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(df, min_freq=3):\n",
    "  counter = Counter()\n",
    "  for col in [\"premise\", \"hypothesis\"]:\n",
    "    for toks in df[col]:\n",
    "      counter.update(toks)\n",
    "\n",
    "  # special tokens\n",
    "  vocab = {\"<PAD>\": 0,\"<UNK>\": 1}\n",
    "  for token, freq in counter.items():\n",
    "    if freq >= min_freq and token not in vocab:\n",
    "      vocab[token] = len(vocab)\n",
    "\n",
    "  return vocab\n",
    "\n",
    "vocab = build_vocab(tokenized_train_df)\n",
    "print(\"Vocab size:\\t\", {len(vocab)})\n",
    "print(\"Sample vocab:\\t\", list(vocab.keys())[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVw81ZCbgjSh"
   },
   "source": [
    "## 3.3 One-hot key embedding\n",
    "\n",
    "Map each token to its one-hot key from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "gg2wWyg-bV3r",
    "outputId": "3c1e4146-0dce-400e-ee98-acc0477feb75"
   },
   "outputs": [],
   "source": [
    "def word_to_index(df, vocab):\n",
    "  df = df.copy()\n",
    "\n",
    "  for col in [\"premise\", \"hypothesis\"]:\n",
    "    df[col] = df[col].apply(lambda toks: [vocab.get(w, vocab[\"<UNK>\"]) for w in toks])\n",
    "\n",
    "  label_map = {\"neutral\": 0, \"entails\": 1}\n",
    "  if \"label\" in df.columns:\n",
    "    df[\"label\"] = df[\"label\"].map(label_map).fillna(-1).astype(int)\n",
    "\n",
    "  return df\n",
    "\n",
    "# One-hot key embedding\n",
    "indexed_train_df = word_to_index(tokenized_train_df, vocab)\n",
    "indexed_val_df = word_to_index(tokenized_val_df, vocab)\n",
    "indexed_test_df = word_to_index(tokenized_test_df, vocab)\n",
    "\n",
    "display(indexed_train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZJlo-z8k0ai"
   },
   "source": [
    "# 4. Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTHB84RcbOFo"
   },
   "source": [
    "## 4.1 Training Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mtl8jwlgCpu3"
   },
   "source": [
    "### 4.1.1 Enable cuda GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9W2gHTTCyM2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyhnsNdv7kVj"
   },
   "source": [
    "### 4.1.2 Shared hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DgNqexCv7fHf"
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "shared = SimpleNamespace(\n",
    "  vocab_size = len(vocab),\n",
    "  embed_dim = 256,\n",
    "  hidden_dim = 256,\n",
    "  num_layers = 1,\n",
    "  dropout = 0.1,\n",
    "  num_classes = 2,      # len(label_mapping)\n",
    "  label_mapping = {\"neutral\": 0, \"entails\": 1},\n",
    "  batch_size = 128,\n",
    "  learning_rate = 1e-3,\n",
    "  total_epoch = 20,\n",
    "  pad_idx = vocab[\"<PAD>\"],\n",
    "  unk_idx = vocab[\"<UNK>\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NWYbjTKb7RE"
   },
   "source": [
    "### 4.1.3 Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3P_ZR8E1b-j4",
    "outputId": "6b350379-f2ea-40a5-8e94-d097ff5b20eb"
   },
   "outputs": [],
   "source": [
    "def pad(seq, max_len):\n",
    "  return seq + [shared.pad_idx] * (max_len - len(seq))\n",
    "\n",
    "def pad_seq(df):\n",
    "  df = df.copy()\n",
    "\n",
    "  max_prem = max(df[\"premise\"].apply(len))\n",
    "  max_hypo = max(df[\"hypothesis\"].apply(len))\n",
    "\n",
    "  df[\"premise\"] = df[\"premise\"].apply(lambda s: pad(s, max_prem))\n",
    "  df[\"hypothesis\"] = df[\"hypothesis\"].apply(lambda s: pad(s, max_hypo))\n",
    "\n",
    "  return df\n",
    "\n",
    "# Padding\n",
    "pad_train_df = pad_seq(indexed_train_df)\n",
    "pad_val_df = pad_seq(indexed_val_df)\n",
    "pad_test_df = pad_seq(indexed_test_df)\n",
    "\n",
    "# Verification\n",
    "pd.set_option(\"display.max_colwidth\", 60)\n",
    "display(pad_train_df.head())\n",
    "pd.reset_option(\"display.max_colwidth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6Gm9F5Mb-0p"
   },
   "source": [
    "### 4.1.4 Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D6cJWrEacAhH"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "def make_batch(pad_df):\n",
    "  batch_size = shared.batch_size\n",
    "\n",
    "  premises_tensor = torch.tensor(pad_df[\"premise\"].tolist())\n",
    "  hypotheses_tensor = torch.tensor(pad_df[\"hypothesis\"].tolist())\n",
    "  labels_tensor = torch.tensor(pad_df[\"label\"].tolist())\n",
    "\n",
    "  dataset = TensorDataset(premises_tensor, hypotheses_tensor, labels_tensor)\n",
    "  loader  = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  return loader\n",
    "\n",
    "train_loader = make_batch(pad_train_df)\n",
    "val_loader = make_batch(pad_val_df)\n",
    "test_loader = make_batch(pad_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67TQJgOJ_lF1"
   },
   "source": [
    "## 4.2 Model 1: The Vanilla NLI Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaiNx53_Sxia"
   },
   "source": [
    "This baseline model is inspired by the classic SNLI model proposed by [Bowman et al.](https://arxiv.org/abs/1508.05326)\n",
    "* Single Bi-LSTM recurrent layer\n",
    "* Dropout applied to encoders and classifier\n",
    "* The value of `label` is either \"neutral\" or \"entails\"\n",
    "* Validation set used for monitoring overfitting\n",
    "* Remains affected by the OOV limitation\n",
    "* No attention mechanism\n",
    "\n",
    "Its ablation counterpart is inspired by the SA-NLI model proposed by [Li et al.](https://www.sciencedirect.com/science/article/pii/S0925231220304793#sec0017), which introduces **dual-attention mechanism** before concatenation.\n",
    "* Inherit from the vanilla model to keep the ablation setup consistent\n",
    "* Overrides the `forward()` method to change model architecture\n",
    "* Combines both self-attention (within each sentence) and cross-attention (between premise and hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKGNh1DeTtPC"
   },
   "source": [
    "![diagrams.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABQAAAALQCAIAAABAH0oBAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAIxlSURBVHhe7d1/kJzVfef7rlqYmkTUZZQKjrxZ68o3YA+GIfLogrEwzCxrG8UxRCGQSCbASDgyARSwvOxqjO1xOXilIiTycsse29dYzqRiAamgNeArLbVT4Ix3gV2yoi5K6brsSEGukmpVu6W69mqnaqfq6lZzxOH0+fH0M91Pn/N9nvN+1ecPOP1MT8/08/3qfPvXtM4CAAAAAJCBlr0AAAAAAEATMQADAAAAALLAAAwAAAAAyAIDMAAAAAAgCwzAAAAAAIAsMAADAAAAALLAAAwAAAAAyAIDMAAAAAAgCwzAAAAAAIAsMAADAAAAALLAAAwAAAAAyAIDMAAAAAAgCwzAAAAAAIAsMAADAAAAALLAAAwAAAAAyAIDMAAAAAAgCwzA6LD18guJwNj3EwAAqJT7jy+REPt+AvrGAIwObt8hEmLfTwAAoFLuP75EQuz7CegbAzA6qF7zk1OLREjo/gAARMAWSFrYAmFAGIDRge4vLXR/AAAiYAskLWyBMCAMwOhA95cWuj8AABGwBZIWtkAYEAZgdKD7SwvdHwCACNgCSQtbIAwIAzA60P2lhe4PAEAEbIGkhS0QBoQBGB3o/tJC9wcAIAK2QNLCFggDwgCMDnR/aaH7AwAQAVsgaWELhAFhAEYHur+00P0BAIiALZC0sAXCgDAAowPdX1ro/gAARMAWSFrYAmFAGIDRge4vLXR/AAAiYAskLWyBMCAMwOhA95cWuj8AABGwBZIWtkAYEAZgdKD7SwvdHwCACNgCSQtbIAwIAzA60P2lhe4PAEAEbIGkhS0QBoQBGB3o/tJC9wcAIAK2QNLCFggDwgCMDnR/aaH7AwAQAVsgaWELhAFhAEYHur+00P0BAIiALZC0sAXCgDAAowPdX1ro/gAARMAWSFrYAmFAGIDRge4vLXR/AAAiYAskLWyBMCAMwOhA95cWuj8AABGwBZIWtkAYEAZgdKD7SwvdHwCACNgCSQtbIAwIAzA60P2lhe4PAEAEbIGkhS0QBoQBGB3o/tJC9wcAIAK2QNLCFggDwgCMDnR/aaH7AwAQAVsgaWELhAFhAEYHur+00P0BAIiALZC0sAXCgDAAowPdX1ro/sjQ0aNHV65cuXHjRvuCwThx4sSZM2fMlYMHD65cubLVag0NDc3NzXmPGZBo3wiAhS2QtLAFwoAwAKNDVd3/Ryd+/qU/eWz8yqtbbxm/8uoHP//wi3/7//zoxM8/tf0zr7/x31589ciFIyP6gD968CH3egaRu+9/sNVqvffSy//jkZ/qxYVDP772n35E3ZL3Xnr5Xx9cCB0ZOXR/NNLx48e3b9+uhsxWqzU6Onr77bcfPnxYXRpzAF5YWGi1WitWrDh16pRaUd99aGho8+bNW7ZsmZmZcY8ZkGjf6OzZs4uLi6tXr47zvYBaYAvEFgiZYABGh0q6/94nn1Ft/b2XXj7750+pxR+d+Llqpq1W67Ir1r7+xn/7yanFF1898o//ybtidn/znxz9HdXi+UNDf31wYesf/pG6hf/X37zqHhk/dH80z+OPP64qq9VqrX+T+m89jMUfgMfHx/Xzrurm7du3r+CYPi0tLd14441DQ0OvvPKKuV75NyrAAAxY2AKxBUImGIDRof/u77Z4M3uffMa86O9+ejpy9/c+qKk6vur+6lJ1Y9wj44fuj4ZRM16r1VIvLdaOHDny27/92/EHYNeOHTusAbhyoQE4JgZgwMIWiC0QMsEAjA59dv9dX/m6auWqk7oHqFabtvtb+dGJn19/w2+q2/CVb8y5B6QN3R9NooauruMlA3AEDMCAhS2Qe0DasAXCgDAAo0M/3d98ac1HfuNG9wB92DXXXS+n+5u3ge4PDFTJl/i6A/CJEyemp6f1e4YnJibc0XF+fn5yclIdMDQ0tHXrVv1dCi4yv5f52mxFzYfu7VEOHjy4bt06deTo6Oju3bv11RbcYDVgW9S8HfpG8/PzN9xwgz54YmJCv19af9XMzIx6Z7U6ZmxszP0VmcoMwAU/hfpdzczMWF9irVu/efNXZN7yo0ePqsPGx8cLbg8wUGyB3APShi0QBoQBGB366f76sc/iNqo/AaKg+6sPkLj819+vLjp/aOjBzz9svppIv53m/KGh6S/ufuLZef0dCy5yP3PCWtE3wz3S/BG8HxdhPZKqX+b0F399QP0gvf3zRvdHk6jZz52aLNYc+PLLL6sZbGJiYtu2bWoUtJ4+VaO1+uQqdYweswsusr7Xyy+/vG3bNjXTqu91//33nzlzxjuXqp9FX626hWqOLb7B8/Pz+nj1tffee68aaL3fSI/l6mA9T+rnqNVXbd68WX12l/sdvboOwMU/hfqm1mMZ1jPb6pZbvyL3l69ueavVWrduXcHtAQaNLRBbIGSCARgdeu7+ZuMrePGPFW/3V4vvvfTyAwt/a35uhPmQqnrLyqNffVx/4IRu8QUXeT9zIvTwp3ukyhPPzrdarV/4xRUHFv5Wfe35Q0PmF6oboLq/esOP/l/3HUFdQ/dHY6jpqMyri605cGFhwfyMaD1Z6QMKXlFccJHizpzuS6DdY9RQPTY2Zk5r8/Pz6kb2fIND32jFihXmtR08eND9zDB1/dZHeblPJmtdB+Din8J7b6pbqw5wJ+SlpSXrd6tvedcXBQARsAUqOFKFLRCagQEYHXru/mYP7bP76+6pWqrqtqrhqk9i0F+le65+jLPgotB3DHV/90jzYVG9oh70NTu7+TCweqWT+akSyw3dH43hHZm83DnQYh0QmieLL1Lc71VmAHaPKVbyBpf/Rua6O2qGFk1dB2CXdfPcGdu8Vd5bbl2D+t9l3QZgcNgCFRzJFghNwgCMDhK6v+6eaqWg+7darXs+/S/NxxQLLnIP6KH769umj1Qr5o9c5mMwyofuj8bocwA+ceLEM888s+1NW7ZssUYv/TrnrVu3Hjt2zPzCgou838ud3EqOr5aCGxy6hvLfyHyrrfsj6Pm2/wG44KewrsH8X31fqxc/a+oa9K3y3nIgFbZABUeyBUKTMACjQyXdv/gNMKGvMh8d/Lf//rXv/NVz6j8+cM116gDd/c2HSNVbUA4s/K3+2oKLvN+xfPe33t9isf49sG5wz6H7o0l6ew/w0tKS/mwnkzU4mZ+3NDY2Zr52t+AidwbrOgB3HR273uDQZFv+G5nPvro/QiUDcNefwvpdma9/1gOwFwMwZGILVHAkWyA0CQMwOvTc/a2222f3V5+y8IFrrvvIb9yo30NiNtO/++lp/a+C9UBjwUXe79hb97durRnd/Xt7x4sVuj+aRI1tBVOZYs1FasoaHx/Xg2vB4KQ+uNj7EVDei9yr6joAh8ZXresNDl1DycPiPAPc9aewhl7z91Zwy03uFQIJsQUqOJItEJqEARgd+un++oU6xX8DwIzbYc3PMFTd0339j3WYYrbagovc79hb9y/4Aen+QIgaeLq+Ctqci7yjVNfBSc2H3u9iXeReVdcB2HuMVuYGe49xDwt9I+vF5O5X9T8Ae2+h+430lbzxxhvWt/Pecot7hUBCbIEKbhtbIDQJAzA69NP9zeZY8NKXH534uXptj7fDlvkECDPqQw7dhzlDF7nfsXz3N2+b9e2eeHbefQMM3R9wqbloaGhobm7OXD9+/PjHP/5x968BuZOY/jBhPTgtLi7qr1X09FVwkfpfdwZzJzf3GO9T2T/4wQ8OHz5c5gZ7v4v3GxV8CnTxC4krH4C9P4X+Vaxfv956cXvobz7rz8oO3XIgFbZA+svdI9kCoUkYgNGhn+5vdUzvA4Tqz8epD+j3dlhr5Ucnfu423L/76emPfuwm6yMH1b8NBReV+Y5du7/5EK9+d81f/PWBWz9xp/5Cuj9QYGlpSb0OWVn/JvXfetyy5iLzz8lu2bJFPYfsfhqT/ou16u2+avQquEh9rTuDuaOpe4x+Dtb7d4C73mDzGPUndguey1W3x/o7wMWv4i4/ALdardHRUXUvKFu3blVfUuan0N/d+5pzfcvVL199Albxow9AQmyBvD8LWyA0DwMwOvTZ/VV/1w+CXnbFWv0BDOoPu1/0jl/Rrd/7h+bMnqs6/p6v/7n+g+zqHwB1jL5y1W3NL/deVOY7Fh+pYr7PR7Eel9UHvPfSy93Ha5cbuj8aaX5+/oYbbtBFNDo6av7JWXcumpub0wPYxMTEq6++unr1avOA48eP609sUh/4rAe/gou836vMAKxm4NnZWX2rRkdHd+/era+56w0+e/asfiBgxYoV3slfO3jw4Lp16/SPYP15Xu9XlR+ALeaXlPkp9GMB3u9l3fKJiYnXXntNX+q95UAqbIEKjlRhC4RmYABGh/67v8rCoR/f8cl7Lv/19+sWOX7l1Q9+/mHz4UD9B+U09YjpE8/Oq/WNt35CNXH1bhbz4c+pbff923//2h2fvEetT39xt7rOgou83/HXLnmv9za4R5qP5u598hn9o2289RPmG2/cz0gs+WEYodD9AQjnPmQA1BFbILZAyAQDMDpU1f1JVaH7A5Cs+L3EQI2wBZIWtkAYEAZgdKD7SwvdH4Bk5l8kBmqNLZC0sAXCgDAAowPdX1ro/gDEcj8sGqgvtkDSwhYIA8IAjA50f2mh+wMAEAFbIGlhC4QBYQBGB7q/tND9AQCIgC2QtLAFwoAwAKMD3V9a6P4AAETAFkha2AJhQBiA0YHuLy10fwAAImALJC1sgTAgDMDoQPeXFro/AAARsAWSFrZAGBAGYHSg+0sL3R8AgAjYAkkLWyAMCAMwOtD9pYXuDwBABGyBpIUtEAaEARgd6P7SQvcHACACtkDSwhYIA8IAjA50f2mh+wMAEAFbIGlhC4QBYQBGB7q/tND9AQCIgC2QtLAFwoAwAKMD3V9a6P4AAETAFkha2AJhQBiA0YHuLy10fwAAImALJC1sgTAgDMDoQPeXFro/AAARsAWSFrZAGBAGYHSg+0sL3R8AgAjYAkkLWyAMCAMwOtD9pYXuDwBABGyBpIUtEAaEARgd6P7SQvcHACACtkDSwhYIA8IAjA50f2mh+wMAEAFbIGlhC4QBYQBGB7q/tND9AQCIgC2QtLAFwoAwAKMD3V9a6P4AAETAFkha2AJhQBiA0YHuLy10fwAAImALJC1sgTAgDMDoQPeXFro/AAARsAWSFrZAGBAGYHRQvYZIi30/AQCASrn/+BIJse8noG8MwOjg9h0iIfb9BAAAKuX+40skxL6fgL4xAKOZ7njsyTsee9JeBQAAaDS2QEAxBmA00OtvnLxo6ksXTX3p9TdO2pcBAAA0FFsgoCsGYDTQHY89qbo/j4ACAIB8sAUCumIARtPoxz55BBQAAOSDLRBQBgMwmkY/9skjoAAAIB9sgYAyGIDRKNZjnzwCCgAAcsAWCCiJARiNYj32ySOgAAAgB2yBgJIYgNFMqu/bqwAAAI3GFggoxgCMZqL7AwCADLEFAooxAKOZ6P4AACBDbIGAYgzAaCa6PwAAyBBbIKAYAzCaie4PAAAyxBYIKMYAjGai+wMAgAyxBQKKMQCjmej+AAAgQ2yBgGIMwGgmuj8AAMgQWyCgGAMwmonuDwAAMsQWCCjGAIxmovsDAIAMsQUCijEAo5no/gAAIENsgYBiDMBoJro/AADIEFsgoBgDMJqJ7g8AADLEFggoxgCMZqL7AwCADLEFAooxAKOZ6P4AACBDbIGAYgzAaCa6PwAAyBBbIKAYAzCaie4PAAAyxBYIKMYAjGai+wMAgAyxBQKKMQCjmej+AAAgQ2yBgGIMwGgmuj8AAMgQWyCgGAMwmonuDwAAMsQWCCjGAIxmovsDAIAMsQUCijEAo5no/gAAIENsgYBiDMBoJro/AADIEFsgoBgDMJqJ7g8AADLEFggoxgCMZqL7AwCADLEFAooxAKOZ6P4AACBDbIGAYgzAaCa6PwAAyBBbIKAYAzCaie4PAAAyxBYIKMYAjGai+wMAgAyxBQKKMQCjmej+AAAgQ2yBgGIMwGgmuj8AAMgQWyCgGAMwmonuDwAAMsQWCCjGAIxmovsDAIAMsQUCijEAo5no/gAAIENsgYBiDMBoJro/AADIEFsgoBgDMJqJ7g8AADLEFggoxgCMZqL7AwCADLEFAooxAKOZ6P4AACBDbIGAYgzAaCa6PwAAyBBbIKAYAzCaie4PAAAyxBYIKMYAXI2tl19IREV1f3edJIxdNgCA+nO7PUkbtkAyY1cO0mEAroZ7lpO0uemDl9/0wcvddZIwdtkAAOrP7fYkbdgCyYxdOUiHAbga587sF1tESNQ98rOnHiYSQusHgKZiCyQtbIGkhV2QNAzA1aD7SwvdX1Ro/QDQVGyBpIUtkLSwC5KGAbgadH9pofuLCq0fAJqKLZC0sAWSFnZB0jAAV4PuLy10f1Gh9QNAU7EFkha2QNLCLkgaBuBq0P2lhe4vKrR+AGgqtkDSwhZIWtgFScMAXA26v7TQ/UWF1g8ATcUWSFrYAkkLuyBpGICrEer+ap0QUhC7nAAA9XGuk7MFImT5scsJUTAAV+PcSUz3J2T5scsJAFAf5zo5WyBClh+7nBAFA3A1zp3Ege7vrpMkUXeH+9IUkip0fwCou9BWJ7ROUoVdkKiwBUqIAbgaoS4fWidJQuuXFro/ANRdaKsTWiepwi5IVNgCJcQAXI1Qlw+tkySh9UsL3R8A6i601Qmtk1RhFyQqbIESYgCuRqjLh9ZJktD6pYXuDwB1F9rqhNZJqrALEhW2QAkxAFcj1OVD6yRJaP3SQvcHgLoLbXVC6yRV2AWJClughBiAqxHq8qF1kiS0fmmh+wNA3YW2OqF1kirsgkSFLVBCDMDVCHX50DpJElq/tND9AaDuQlud0DpJFXZBosIWKCEG4GqEunxonSQJrV9a6P4AUHehrU5onaQKuyBRYQuUEANwNUJdPrROkoTWLy10fwCou9BWJ7ROUoVdkKiwBUqIAbgaoS4fWidJQuuXFro/ANRdaKsTWiepwi5IVNgCJcQAXI1Qlw+tkySh9UsL3R8A6i601Qmtk1RhFyQqbIESYgCuRqjLh9ZJktD6pYXuDwB1F9rqhNZJqrALEhW2QAkxAFcj1OVD6yRJaP3SQvcHgLoLbXVC6yRV2AWJClughBiAqxHq8qF1kiS0fmmh+wNA3YW2OqF1kirsgkSFLVBCDMDVCHX50DpJElq/tND9AaDuQlud0DpJFXZBosIWKCEG4GqEunxonSQJrV9a6P4AUHehrU5onaQKuyBRYQuUEANwNUJdPrROkoTWLy10fwCou9BWJ7ROUoVdkKiwBUqIAbgaoS4fWpeTfrjXJjzCW7/9++2Ve81iQ/cHgLoLbXVC63LSD/fa5IddkKiwBUqIAbgaoS4fWpeTfrjXJjy0fmmh+wNA3YW2OqF1OemHe23ywy5IVNgCJcQAXI1Qlw+tkyQR3vozDN0fAOoutNUJrZNUYRckKmyBEmIArkaoy4fWSZLQ+qWF7g8AdRfa6oTWSaqwCxIVtkAJMQBXI9TlQ+skSWj90kL3B4C6C211QuskVdgFiQpboIQYgKsR6vKhdZIktH5pofsDQN2FtjqhdZIq7IJEhS1QQgzA1Qh1+dA6SRJav7TQ/QGg7kJbndA6SRV2QaLCFighBuBqhLp8aJ0kCa1fWuj+gDQnTpw4c+aMvQqEhbY6oXWSKuyCRIUtUEIMwNUIdfnQuqi88BX7E+Qta1a1Jte27r6pdWTO/tp6RX7r//7MXfZv/y1dj1l90Ur3CoWH7h/f0tLS9PT0ypUr1WkzMTGxf/9++yCcPfv444+rX9G+ffvsy5prYWGh1WqtWLHi1KlT9mUDsLi4uHr16mjfDgMS2uqE1qWl2MgF7S3QputbBx6xv7B2kb8LWn3RuX+bLN+fuUsfY1/2lsNf/Yx7hZLDFighBuBqhLp8aF1a9n2hNTzU0UfWXtzu+Fe/r2Ox1WptuKq1+Lz95XWJ/Nb/s6cefvqzdw6ff575O3/Pr140/+VPmcd8+/7ftY659rJ316710/3jU/NGq9UaHR3dtm3bli1b1PlT+Yy3tLR04403Dg0NvfLKK/ZldaBuv/rlbNy40b64/kJ3kBqAx8fH4zwJzADcDKGtTmhdWl76Wmu03Rffph73n1xrb41GV9f7mQD5u6BX99x/5SXv6vilt1p7/uAm85j5L3/qPb96kXnAhSuGzQm5LmELlBADcDVCXT60LjCbrjebSftpYX3Rrm0dF2263v7aukR+61e55ZorzF+41fq9x3z3wdvcY+SH7h+ZelbTnOiOHz9+yy23MABbjh49unLlyhtuuKGp45mQO4gBuBlCW53QusDM7jD/RW3NTL190YFH2k8Ca2tWtU4/Z395XVKLXdDTn73TvC+uvORd7jF7/uAm85i7PnKVe4z8sAVKiAG4GqEuH1oXmKkNZjPpGIDPvtja+KGiS+uSWrT+nz318PStHY9GfPv+33WPuW1y3Dymjo990v0j089qVj7uuoTMVz1TjxTs27dvx472vjjCbywyIXcQA3AzhLY6oXWB2bvT/Be1YwA++2Jrz30dlz5wi/3ldUktdkHW+7xumxx3j5m952bzmOlbr3ePkR+2QAkxAFcj1OVD6wJTPADv+0LHpXvus7+8FqlF63cHYO9wywCMHqhxbmZmxr6g0/z8/OTkpDq1hoaGdu/ebb4gVj07OjMzc/z48e3bt6vDxsbG9CilvovFnCH7vH7TwYMH161bp44ZHR21rqr4G4Wo4VBNZaGXBC8tLenbZjKfXS8+Rv+YR48eVTdyfHxcz4Fdb3nxlavPsrLe7F3mDlK3yn3V9/z8/A033KAPnpiYOHz4sHnAsu41resAXPBTqAcp3JPZXS/+ZRbfESgjtNUJrQtM8QC8+HzHpZNr7S+vS2qxC2IARgQMwNUIdfnQusAUD8Avfa3j0qkN9pfXIrVo/QzAGBw1zg0NDc3NzdmXvUXND0NDQ5s3b962bZuaPcwJUA0MmzdvXrly5dDQ0LZt29RopJ9OnJ+f11+oruTee+/V81L/16+pQc66Kj1pd/1GIeq3pIZA7zOl+q3UExMT27ZtUxO4uqn6E8W6HmP+mK1Wa926dXoO7HrLu175yy+/rL5KHVD+DvIOwPrzwNTBepg0H9Qof6+Zigfg4p9CfUfrDnXvr66/zII7AiWFtjqhdYEpHoDPvtha9UtvXzpygX1pXVKLXRADMCJgAK5GqMuH1gWmeAA+9K2OS+++yf7yWqQWrZ8BGAM1PT2tzhk1BlvToDtULC0tWS8DVseoEVEfZr272J1DzK/t//r1mDo2NmbOKvPz8+YgV/yNQnbs2OFOUOYzitaK94fteoz+Ma0Rrswt73rlCwsLt99+u/kk7bLuIPf3vGLFCvPaDh48aH1YdMl7zVI8ABf/FN6X9JsPXpT8ZYbuCJQX2uqE1gVmWQPwql+yL61LarELYgBGBAzA1Qh1+dC6wBQPwNZLoHdts7+8FqlF62cAxqBZrwg1nw32jojWUOQOFe5iaL6q6vpDV6V5L3WnO5caydxnCK1v7R13zW/X9Rh1te7sV+aWd71yl3UNoTvI/RV5b4+77v6WQoum4gHYZd08d8C2bpX3xnvPt/K3Aa7QVie0LjDFA/Dp5zou5SXQAw0DMCJgAK5GqMuH1gWmeAB+4Ja3Lxoeap182v7yWqQWrZ8BGHEcOXJEj8HquUT9lJp6saim/lqSHmPcGcmdG73z1aCvXyv5jbzUU4jm873uM41l5s+ux3h/zJK3vOuVKydOnHjmmWfMa1juABw6zH0W2vvjuI8mWMoMwAU/hfXl1v+W/GV6bzmWJbTVCa0LTPEAfOCRjktr+jEoddkFMQAjAgbgaoS6fGhdYAoGYOsfhpq+/rkurd8dgMtgAEZv1BijZgY9MHgVDwxlBtQKr794cCr5jbzUc4bqTaeaeqTAeuKx4BXIZY7x/pglb3nXK+/6EVnulyjWrSr4PVvPvnp/nD4H4K4/hfUcr/X655K/TO8tx7KEtjqhdYEpGICPPdH+00fa6Or2Z2K511CL1GIXZA3AZTAAY7kYgKsR6vKhdYGxBuCpDe1/AB64pf1SH9OGq2j9Aw8DMKJRE4gahEJDkcU7MJQfgAd3/VrxpQXUt7ar6y16TtOHmZ9BZd3grsd4f8ySt7zrlauxcHx8XL+BtuRTuyUPc4dw74/T5wDc9aewhl7rBc8FN97kXieWK7TVCa0LjDUAT65tb4Fmptp7Huvdv0fm7K+tUWqxC2IARgQMwNUIdfnQusBYA7BrdHX7Xwj3C2uUWrR+dwD2Dre8BBqVMAdgd4Tw8g4MJQfUqq6/61UVXxpiDXWafi5x3759+kfbsmWLmkLdv6xT5hjvj1nmlne9cu8vv+Rk694q7+0xfyFqxf1C771mKRiAvbfQ/S76Gt544w33e3lvvMW9TixXaKsTWhcYawB2rfql1s5PtN8M7H5tjVKLXRAvgUYEDMDVCHX50LrAeJ8Bnplq/6vwwlfaLwFyv6R2qUXrZwDGgBw9enRiYkL/nR41Y+gn2dTYEPqzt/rTlUMDgzvqeGePCq9fDavWVf3gBz9Q11PmG1m8E5emX/Grbon16dOWMsd4f8wyt7zrlbs/iL6ju0627q0q+BRo80a6X+i91yzLGoC9P4W+a9avX+8+eNH1lxm65ViW0FYntC4woWeA99zX3gId+pZ9fE1Ti10QAzAiYACuRqjLh9YFpuA9wI1JLVo/AzAGRG301QkzOjqqBgb3L7WqGUO/vFZ9YlAPz/WpsUT/SVj95VVdv34SMvR3gLt+I4v6vu6wpJhPlS8sLFivlF6/fr31B3u6HuP9MZWut7zrletf/ubNm/UTxdbo6L2DvLdK3x7z7wB3fW7We69Z1AH6hNS2bt165syZMj+FeWJ7H7zo+sv03nIsS2irE1oXmIL3ADcptdgFMQAjAgbgaoS6fGhdYBiA5YQBGANy/Pjx7du360FiaGhITRrWYQcPHlRvK1XHTExMvPbaa/pS78DgHXX03xxesWKFOZlUdf1LS0uzs7PmVG+9zLj4G1lCr3/W1Cg1MzOj/mNsbEx/Spb6LuYA1vUY74+pFd/yrld+9uzZubk5/ZuZmJh49dVXV69ebX079w4K3Srr9ljTfugLvfeaSQ/AFv0lZX4K/VBI6BsV/zK9txzLEtrqhNYFhgFYThiAEQEDcDVCXT60LjAMwHLCAAyIZX3UsGbOz2WO6dlAr7ymvC/nRjShrU5oXWAYgOWEARgRMABXI9TlQ+sCwwAsJwzAgFhq/ty6dau5qN+eqmawMsf0bKBXXkcFbyRGHKGtTmhdYBiA5YQBGBEwAFcj1OVD6wLDACwn1gD83Qdvc49hAAaS0K/aVe+eVW8rVS/T1S/BLXNMzwZ65XVk/UVixBfa6oTWBYYBWE4YgBEBA3A1Ql0+tC4w1gC87wv2AQ1ILVr/z556+K6PXGXeF7P33OwewwAMpHLixInp6Wn9tlL1GVRzc3Pm8FnmmJ4N9Mrrxf2waMQX2uqE1gXGGoDvvsk+oBmpxS7IGoA/vPYS9xhrAL7rI1e5x8gPW6CEGICrEeryoXVpOfl0x596b7Vam663j2lAatH6f/zNnb8ycoF5X3x47SWn/vKLxcd4HyKVH7o/ANRdaKsTWpeWxedbGzoedm6tWVX7P/nrTS12Qdbj+78ycsGPv7nTPODUX37xw2svKT6mFmELlBADcDVCXT60LiqHvmW2kbeNXNAejN3j6xv5rf+Hj9w7fP559j3Ral24Ytg8xr74TVesead7hcJD9weAugttdULr0tL5ePLbDjxiH1n3yN8FXbHmnfbd8KYfPnKvPubCFcP2xa3W8Pnn1W4GZguUEANwNUJdPrQuKqefa7/j15vF5+2Dax35rf+nez/3/Zm7vOl6zPyXP+VeofDQ/QGg7kJbndC6tLibH5WGPQdQi13Q/Jc/5W5vvj9z10/3fk4f416qYr1WTn7YAiXEAFyNUJcPrZMkkd/6cwvdHwDqLrTVCa2TVGEXJCpsgRJiAK5GqMuH1kmS0Pqlhe4PAHUX2uqE1kmqsAsSFbZACTEAVyPU5UPrJElo/dJC9weAugttdULrJFXYBYkKW6CEGICrEeryoXWSJLR+aaH7A0DdhbY6oXWSKuyCRIUtUEIMwNUIdfnQOkkSWr+00P0BoO5CW53QOkkVdkGiwhYoIQbgaoS6fGidJAmtX1ro/gBQd6GtTmidpAq7IFFhC5QQA3A1Ql0+tE6ShNYvLXR/AKi70FYntE5ShV2QqLAFSogBuBqhLh9aJ0lC65cWuj8A1F1oqxNaJ6nCLkhU2AIlxABcjVCXD62TJKH1SwvdHwDqLrTVCa2TVGEXJCpsgRJiAK6GOolDcXsQSRJav7TQ/QGg7txtD1sgmWEXJCpsgRJiAK6G2/Hp/gJD65cWuj8A1J277WELJDPsgkSFLVBCDMCDRfcXFVq/tND9AaCp2AJJC7sgUWELlBAD8GDR/UWF1i8tdH8AaCq2QNLCLkhU2AIlxAA8WHR/UaH1SwvdHwCaii2QtLALEhW2QAkxAA8W3V9UaP3SQvcHgKZiCyQt7IJEhS1QQgzAg0X3FxVav7TQ/QGgqdgCSQu7IFFhC5QQA/Bg0f1FhdYvLXR/AGgqtkDSwi5IVNgCJcQAPFh0f1Gh9UsL3R8AmootkLSwCxIVtkAJMQAPljq5CSEFscsGAFB/brcnhFixywZRMAAPlnuiE0Ks2GUDAKg/t9sTQqzYZYMoGICRlzsee/KOx560VwEAABqNLRCgMAAjI6+/cfKiqS9dNPWl1984aV8GAADQUGyBAI0BGBm547EnVffnEVAAAJAPtkCAxgCMXOjHPnkEFAAA5IMtEGBiAEYu9GOfPAIKAADywRYIMDEAIwvWY588AgoAAHLAFgiwMAAjC9ZjnzwCCgAAcsAWCLAwACMvqu/bqwAAAI3GFghQGICRF7o/AADIEFsgQGEARl7o/gAAIENsgQCFARh5ofsDAIAMsQUCFAZg5IXuDwAAMsQWCFAYgJEXuj8AAMgQWyBAYQBGXuj+AAAgQ2yBAIUBGHmh+wMAgAyxBQIUBmDkhe4PAAAyxBYIUBiAkRe6PwAAyBBbIEBhAEZe6P4AACBDbIEAhQEYeaH7AwCADLEFAhQGYOSF7g8AADLEFghQGICRF7o/AADIEFsgQGEARl7o/gAAIENsgQCFARh5ofsDAIAMsQUCFAZg5IXuDwAAMsQWCFAYgJEXuj8AAMgQWyBAYQBGXuj+AAAgQ2yBAIUBGHmh+wMAgAyxBQIUBmDkhe4PAAAyxBYIUBiAkRe6PwAAyBBbIEBhAEZe6P4AACBDbIEAhQEYeaH7AwCADLEFAhQGYOSF7g8AADLEFghQGICRF7o/AADIEFsgQGEARl7o/gAAIENsgQCFARh5ofsDAIAMsQUCFAZg5IXuDwAAMsQWCFAYgJEXuj8AAMgQWyBAYQBGXuj+AAAgQ2yBAIUBGHmh+wMAgAyxBQIUBmDkhe4PAAAyxBYIUBiAkRe6PwAAyBBbIEBhAEZe6P4AACBDbIEAhQEYeaH7AwCADLEFAhQGYOSF7g8AADLEFghQGICRF7o/AADIEFsgQGEARl7o/gAAIENsgQCFARh5ofsDAIAMsQUCFAZg5IXuDwAAMsQWCFAGPgBvvfxCIi32nZSTzLu/ezKQ5LHvJABN4dY7kRD7fsoGWyAiMPb9FAUDcI6x76Sc0P2JtNh3EoCmcOudSIh9P2WDLRARGPt+iiLSAHz2xRaRkISnmhB0/62XX/izpx4mEkI9As3GFkhaMu+6bIHYAolKwnpkAM4rCU81Iej+dH85oR6BZmMLJC2Zd122QGyBRCVhPTIA55WEp5oQdH+6v5xQj0CzsQWSlsy7LlsgtkCikrAeGYDzSsJTTQi6P91fTqhHoNnYAklL5l2XLRBbIFFJWI8MwHkl4akmBN2f7i8n1CPQbGyBpCXzrssWiC2QqCSsRwbgvJLwVBOC7k/3lxPqEWg2tkDSknnXZQvEFkhUEtZjmgFYLRJpse+8JqL70/3lJJ+6A/J0rsYDYxgRFfvOayK2QGyBRCVh6TEAk7dj33lNRPd3u797JhAJse88AHVzrpYZgOsQ+85rIrZA7haIXZDM2Hde1VIOwO4/CSRV4pxtEtD93e7v9h0iIfadB6BuztVy6N9cZ50kST4tly2QuwViFyQz9p1XNQZg0k6cs00Cur/b/b2LJGHyqUeg2UK7ndA6SZJ8Wi5bIO9uJ7ROkiROPTIAk3binG0S0P3dLu9dJAmTTz0CzRba7YTWSZLk03LZAnl3O6F1kiRx6pEBmLQT52yTgO7vdnnvIkmYfOoRaLbQbie0TpIkn5bLFsi72wmtkySJU48MwKSdOGebBHR/t8t7F0nC5FOPQLOFdjuhdZIk+bRctkDe3U5onSRJnHpkACbtxDnbJKD7u13eu0gSJp96BJottNsJrZMkyaflsgXy7nZC6yRJ4tQjAzBpJ87ZJgHd3+3y3kWSMPnUI9Bsod1OaJ0kST4tly2Qd7cTWidJEqceGYBJO3HONgno/m6X9y6ShMmnHoFmC+12QuskSfJpuWyBvLud0DpJkjj1yABM2olztklA93e7vHeRJEw+9Qg0W2i3E1onSZJPy2UL5N3thNZJksSpRwZg0k6cs00Cur/b5b2LJGHyqUeg2UK7ndA6SZJ8Wi5bIO9uJ7ROkiROPTIAk3binG0S0P3dLu9dJAmTTz0CzRba7YTWSZLk03LZAnl3O6F1kiRx6pEBmLQT52yTgO7vdnnvIkmYfOoRaLbQbie0TpIkn5bLFsi72wmtkySJU48MwKSdOGebBHR/t8t7F0nC5FOPQLOFdjuhdZIk+bRctkDe3U5onSRJnHpkACbtxDnbJKD7u13eu0gSJp96BJottNsJrZMkyaflsgXy7nZC6yRJ4tQjAzBpJ87ZJgHd3+3y3kWSMPnUI9Bsod1OaJ0kST4tly2Qd7cTWidJEqceGYBJO3HONgno/m6X9y6ShMmnHoFmC+12QuskSfJpuWyBvLud0DpJkjj1yABM2olztklA93e7vHeRJEw+9Qg0W2i3E1onSZJPy2UL5N3thNZJksSpRwZgf/rhXpv8xDnbJKD7u13euygndoH1yr1mscmnHoFmC+12Quty0g/32oQnn5bLFsi72wmtC4ldYL1yr1lm4tQjA7A//XCvTX7inG0S0P3dLu9dlBO7wHrlXrPY5FOPQLOFdjuhdTnph3ttwpNPy2UL5N3thNaFxC6wXrnXLDNx6pEBmLQT52yTgO7vdnnvIkmYfOoRaLbQbie0TpIkn5bLFsi72wmtkySJU48MwKSdOGebBHR/t8t7F0nC5FOPQLOFdjuhdZIk+bRctkDe3U5onSRJnHpkACbtxDnbJKD7u13eu0gSJp96BJottNsJrZMkyaflsgXy7nZC6yRJ4tQjAzBpJ87ZJgHd3+3y3kWSMPnUI9Bsod1OaJ0kST4tly2Qd7cTWidJEqceGYBJO3HONgno/m6X9y6ShMmnHoFmC+12QuskSfJpuWyBvLud0DpJkjj1yABclCNzrRe+4s+xJ+yDa504Z5sEdH+3y3sXScLkU49As4V2O6F1UTn9nL3z0Tn0LfvgWieflssWyLvbCa2TJIlTjwzARZnaYH+GuGvtxa27b2qPyu6X1yhxzjYJ6P5ul/cuisoPH7n32sve7Y0+5unP3uleeu1l777lmivcKxSefOoRaLbQbie0LiovfMXe8LjWrGpt/FDrwCP219Yr+bRctkDe3U5oXU7cvY3KDx+5t+sxP/7mTvcKJSdOPTIAd8me+zp6/fBQa3LtuVjuvsn+2holztkmAd3f7fLeRVH56d7P3TY5blXc8PnnTd96vT7mx9/cecs1V1jHXLhiePaem90rFJ586hFottBuJ7QuLS99rb3tMa29+NwWaOSCjvXR1e1njN1rqEXyablsgby7ndC6nEzfev2FK4Y7Sq7VuuWaK36693PmMcPnn2cds2Pjdaf+8ovuFUpOnHpkAO4e05pVb6+ffq616fqOS3dts7+2LolztklA93e7vHdRYD689hKz3MzpV+c9v3qReUwdp99o3R/AoIV2O6F1gbH2OS985e2Ldm3ruGhyrf21dUk+LZctkHe3E1oXlS9+4qNmuZmvgNOZvrWjXG+bHHePkZ849cgA3D1rVr19MpkD8NkXW4vPt1b9knmytVfca5CfOGebBHR/t8t7FwXGehL46c/e6R7z8SsvNY/5/sxd7jHyk089As0W2u2E1gXGei+YOQCffbH9+mdTTV8LnU/LZQvk3e2E1kXl6c/eadaad7idvedm8xjv8wTyE6ceGYC7p2AAPvti64FbzJOt/Xoh9xrkZ+vlF6q2SJqd8Rt/z+3ytWj97gDsHW6tY17dc797jPzE6f4ABi202wmtC0zxALz/4Y5La/o6OLZAmcS7BarLLuj7M3eZtbZj43XuMQzA5TEAd0/xAGy9SXjvTvuAWoTun0m83b8Wrd8dbssMwIe/+hn3GPmJ0/0BDFpotxNaF5jiAfjQtzoundpgf3ktwhYok3i3QHXZBVkDsHe4ZQAujwG4e5Y1AO9/2D6gFolztiE5b5f3LgoMAzCAegntdkLrArOsAfiBW+wvr0VouZkI7XZC66LCAFwtBuDuKR6Arc+HqOnfQ4pztiE5b5f3LgoMAzCAegntdkLrAlM8AO/7QselszvsL69FaLmZCO12QuuiwgBcLQbg7ikYgBef77h07cX219Ylcc42JOft8t5FgWEABlAvod1OaF1gigfgu296+6LhodbJp+0vr0VouZkI7XZC66LCAFwtBuDuKRiAC/48QL0S52xDct4u710UGGu4vW1yfPrW661csead5jEMwAASCu12QusCUzAA793ZcdGe++yvrUtouZkI7XZC66JiDcDXXvZudwtk/SEMBuACDMDdYw7AIxe0ZqbamVzbsT48VNePv1KJc7YhOW+X9y4KjDUAl8EADCCh0G4ntC4w1gA8taG9Bdr4ofZL3jS2QKiF0G4ntC4q1gBcBgNwAQbg7jEHXdfIBe3ngWv61l+dOGcbkvN2ee+iwFgD8O47P/b9mbusfHjtJeYxDMAAEgrtdkLrAmMNwK4NV9X45W8qtNxMhHY7oXVRsQbg2ybH3S3Qjo3XmccwABdgAO4ecwBe9UvtRq9z6Fv2wTVNnLMNyXm7vHdRYHgPMIB6Ce12QusCYw3Ae+7r2AUtPm8fX8fQcjMR2u2E1kWF9wBXiwG4ewreA9yYxDnbkJy3y3sXBYYBGEC9hHY7oXWBKXgPcGNCy81EaLcTWhcVBuBqMQB3DwMwGsPb5b2LAsMADKBeQrud0LrAMACjMUK7ndC6qDAAV4sBuHsYgNEY3i7vXRQYBmAA9RLa7YTWBYYBGI0R2u2E1kWFAbhaDMDdwwCMxvB2ee+iwDAAA6iX0G4ntC4wDMBojNBuJ7QuKgzA1WIA7h7rzx25BzQgcc42JOft8t5FgbGG26c/e2fXY17dc797jPxQj0AzhHY7oXWBYQBGY4R2O6F1UbEG4B0br3OPYQAujwG4e4aHzNPJvrQZiXO2ITlvl/cuCow13M7ec7N7zC3XXGEe432WWH6oR6AZQrud0LrAbLre7Kn1/nu/odByMxHa7YTWReW7D95mVuJtk+PuMQzA5TEAd8mubea51DYz1ZDP/TcT52xDct4u710UmCvWvNOsRG9nf8+vXmQes/vOj7nHyA/1CDRDaLcTWpeWl75mPwew4arWyaftw+oeWm4mQrud0LqoTN/a8VjUFWve6R5z10euMo/5+JWXusfIT5x6ZAAuSujvvzfvncBxzjYk5+3y3kVROfzVz1x72bvtOux8BPSHj9x75SXvsg4YPv8878uEhId6BJohtNsJrYvKC1+xGurbjj1hH1zr0HIzEdrthNblxHoFnHLlJe8yP+jEe8yH117y072fc69QcuLUIwNwUY7MdfzBd52XvmYfWffEOduQnLfLexdF5fBXPzN96/Xe6GN++Mi97qXTt15fxyeBqUegGUK7ndC6qJx+zt786DTsdXC03EyEdjuhdTlx9zYq5gDsXqrCAOzFAEzaiXO2ITlvl/cukoShHoFmCO12QuskSWi5mQjtdkLrJEni1CMDMGknztmG5Lxd3rtIEoZ6BJohtNsJrZMkoeVmIrTbCa2TJIlTjwzApJ04ZxuS83Z57yJJGOoRaIbQbie0TpKElpuJ0G4ntE6SJE49MgCTduKcbUjO2+W9iyRhqEegGUK7ndA6SRJabiZCu53QOkmSOPXIAEzaiXO2ITlvl/cukoShHoFmCO12QuskSWi5mQjtdkLrJEni1CMDMGknztmG5Lxd3rtIEoZ6BJohtNsJrZMkoeVmIrTbCa2TJIlTjwzApJ04ZxuS83Z57yJJGOoRaIbQbie0TpKElpuJ0G4ntE6SJE49MgCTduKcbUjO2+W9iyRhqEegGUK7ndA6SRJabiZCu53QOkmSOPXIAEzaiXO2ITlvl/cukoShHoFmCO12QuskSWi5mQjtdkLrJEni1GOkAdgbtweRVIlztiE5twx13B5EUoV6BJrB7bRm3H+LSZLQcjPh1qAZ999ikiRx6pEBmLQT52xDcm4Z6rg9iKQK9Qg0g9tpzbj/FpMkoeVmwq1BM+6/xSRJ4tTjwAdgL1q/tMQ52yATrV9aqEeg2dgFiQotN3PsgkQlTj0yAJN24pxtkInWLy3UI9Bs7IJEpWvLVQcQabHvp16pa3P/LSZJUu2dG8IATNqJc7ZBJlq/tFCPQLOxCxKVri3XHb2IhNj3U6/Utbn/FpMkqfbODWEAJu3EOdsgE61fWqhHoNnYBYlK15Z77oADB4iQdL3LloVdkKhUe+eGMACTduKcbZCJ1i8t1CPQbOyCRKVry2UAlpaud9mysAsSlWrv3BAGYNJOnLMNMtH6pYV6BJqNXZCodG25DMDS0vUuWxZ2QaJS7Z0bknIAJtJi30/Ig7r33R5EUoV6BJrN/feXJI99JxnOHeCMYSRVut5ly6Kuzf23mCRJtXduCANw2dxy1cW3XHWxu96k2PcT8uCeCURC7PsJQFO49U6Sx76TDOcOcMYwkipd77JlcU8Gkjz2nVS1NANwHd3x2JN3PPakvQrUn9t35IcHpAAgmsy3QOd6sjOGkVSp9l9J999fkjz2nVQ1BuBSXn/j5EVTX7po6kuvv3HSvgxAdJnvxgAgGrZA53bkzhhGUiXOjCQT9VgJBuBS7njsSXW2secGkqP7A0A0bIEYgKUl5wGYeqwEA3B3erfNnhuQgO4PAHGwBWIAFphsB2DqsSoMwN3p3TZ7biA5uj8ARMMWiAFYYLIdgKnHqjAAd2HtttlzA2nR/QEgDrZACgOwtOQ5AFOPFWIA7sLabbPnBhKi+wNANGyBFAZgaclzAKYeK8QAXJY6z+xVABHR/QEgvsy3QAzA0pLnAKxlXo+VYAAui7MNkIN6BIBoMm+5DMDSwgCccz1WggG4LM42QA7qEQCiybzlMgBLCwNwzvVYCQbgsjjbADmoRwCIJvOWywAsLQzAOddjJRiAy+JsA+SgHgEgmsxbLgOwtDAA51yPlWAALouzDZCDegSAaDJvuQzA0sIAnHM9VoIBuCzONkAO6hEAosm85TIASwsDcM71WAkG4LI42wA5qEcAiCbzlssALC0MwDnXYyUYgMvibAPkoB4BIJrMWy4DsLQwAOdcj5VgAC6Lsw2Qg3oEgGgyb7kMwNLCAJxzPVaCAbgszjZADuoRAKLJvOUyAEsLA3DO9VgJBuCyONsAOahHAIgm85bLACwtDMA512MlGIDL4mwD5KAeASCazFsuA7C0MADnXI+VYAAui7MNkIN6BIBoMm+5yx2Al557bva++9a/732tt6x/3/t2b9167DvfWXruuX95661n/s2/cb9KbBa/973V73jHvp073YtShQE453qsBANwWZxtgBzUIwBEk3nLXdYAfPDhh1decEGr1Rpbs2b/F76gFpeee276935PDcPjF19crwH48U9/utVqbfzgB92LrCw8+qh3Tg6t9xwG4JzrsRIMwGVxtgFyUI8AEE3mLbf8AFw85R58+OHQRWKz9NxzN37gA61Wa+i88175ylfcA3RCTxSH1vsJA3DO9VgJBuCyONsAOahHAIgm85ZbcgBWz5QWz4o7br65XgPwwqOP6hdyz9x2m3uAip6TrUE3tN5nGIBzrsdKMACXxdkGyEE9AkA0mbfcMgPw0b171Sufi18tfHTv3g+///01GoB33HyzHoBDo/vxubnJK65Qx5iDbmi9/zAA51yPlWAALouzDZCDegSAaDJvuWUGYP30b/Gwpz8ESz81qqjZcn737nWXXGI913rw4YfVovW+Yn2F6nXXQ+ed9+gnP2m+27bgopJR4/qnPvaxgh9t4dFH9eSvjV98sX4vtLX++uysub5v586je/eqOXlszZpTTzzh3gw3DMA512MlGIDL4mwD5KAeASCazFtu1wHYnGYLXv/sRj+/qiZGPRbq51rVXL1iePjw179+fG5u9TveYY3H6hrm/vk/15+/pWfUgotK5vFPf3rmttu6Prmt3uWrDjC/RWjdvMI/vuMOcx4OPclshQE453qsBANwWZxtgBzUIwBEk3nL7ToAm5PesgZg83lj9dJo9ZytGnH1oKgnXn28mif199XjpX6at+Cikln83vfet3r1qSeeMMf7FcPD7pO0oUE3tG4OwOrXpd9pXPK3xwCccz1WggG4LM42QA7qEQCiUS0320QYgL1fpZ8f1gOwHhTVM7Hm931o0ybzudOCi0pm4dFHt370o+q/zUHd/Sis0KAbWjcHYGvU9/4e3Kh7xL2nsopdpVgOBuCyONsAOahHAIjG3XxnlWUNwN43yoaiB0v3mVXv9KgHYH28+SFVY2vWHP761/U1FFxUJtO/93t6FjVHVvdVyt6bWrBuXptaZwDuIXaVYjkYgMvibAPkoB4BIJrMW27XAdiaNnsYgEtOle4AvPi97+lPWrYGyIKLzD9upFkzqvVp1foHdGdU700tWK9qALbvp2xkXo+VYAAui7MNkIN6BIBoMm+5ZQZgc6T0flKUN/0PwOanPbtXFbqo6wBsvubZZf2A3ptasM4A3KfM67ESDMBlcbYBclCPABBN5i23zADc9ZOi9GHPf/nL+n8LBmDve4D18e6Mrf/skDtDFlzkjf74K2tRT7PWDxgadEPrDMB9yrweK8EAXBZnGyAH9QgA0WTecssMwNa85w6oZw8cOD43d8O6dervEqkUD8D6eVp3AFZz4+L3vvfb69frL9R/M+nUE08UXOTeMCvqrx9519V3tz4Ky/zB1Z9NevSTnyxYZwDuU+b1WAkG4LI42wA5qEcAiCbzlltyAFYjrn4eePzii/XnTi0999zsffetWrnSnH7N53jH1qzxjqbqBczW3wHWH86sJkz9jdSAqkbTgosKsvTcc4/94R+GjjQHWv0XhlXMt0CbQ6x33R2AFx59VA/A5nPFoTAA51yPlWAALouzDZCDegSAaDJvueUHYJXjc3Pbb7pp3SWX6Nlv/fvet3vrVvM5XvMl05p39jv48MP6qkbf9S5z7Fz83vfu37jxyDe/uf2mm9T0qJ5iLb4oFPcm6dvjXqToJ7r1AWNr1phP4brr5vSr/PEdd5grZZ4EZgDOuR4rwQBcFmcbIAf1CADRZN5ylzsAk0GHATjneqwEA3BZnG2AHNQjAESTectlAJYWBuCc67ESDMBlcbYBclCPABBN5i2XAVhaGIBzrsdKMACXxdkGyEE9AkA0mbdcBmBpYQDOuR4rwQBcFmcbIAf1CADRZN5yGYClhQE453qsBANwWZxtgBzUIwBEk3nLZQCWFgbgnOuxEgzAZXG2AXJQjwAQTeYtlwFYWhiAc67HSjAAl8XZBshBPQJANJm3XAZgaWEAzrkeK8EAXBZnGyAH9QgA0WTechmApYUBOOd6rAQDcFmcbYAc1CMARJN5y2UAlhYG4JzrsRIMwGVxtgFyUI8AEE3mLZcBWFoYgHOux0owAJfF2QbIQT0CQDSZt1wGYGlhAM65HivBAFwWZxsgB/UIANFk3nIZgKWFATjneqwEA3BZnG2AHNQjAESTectlAJYWBuCc67ESDMBlcbahAdS/GQ3ITR+8/KYPXu6u1zH2nQQAwmS+BTrXq50xjKRK5v96Zl6PlRj4AOzu9moadba563WMfSchG+7JQJLHvpMANIVb7zXNhz664UMf3eCu1zT2/dTNua9yxjCSKv3cjw1I5vVYCQbgsrn0d7Zd+jvb3PU6xr6TkA11Avzk1CKREOoRaDb3318iIfb91M25r3LGMJIq/dyPRFrs+ymKSAOwu/MjSZLwVIME1KOoUI9As6ka///+80EiJL113XNf5YxhJFX6uR/ds4KkSm/3YyUYgPNKwlMNElCPokI9As3Ghltaeuu6DMDS0s/96J4VJFV6ux8rwQCcVxKeapCAehQV6hFoNjbc0tJb12UAlpZ+7kf3rCCp0tv9WAkG4LyS8FSDBNSjqFCPQLOx4ZaW3rouA7C09HM/umcFSZXe7sdKMADnlYSnGiSgHkWFegSajQ23tPTWdRmApaWf+9E9K0iq9HY/VoIBOK8kPNUgAfUoKtQj0GxsuKWlt67LACwt/dyP7llBUqW3+7ESDMB5JeGpBgmoR1GhHoFmY8MtLb11XfVVRFrs+6kb9VXuWUFSpbf7sRIMwHkl4akGCahHUaEegWZjwy0tvXVdd/QiEmLfT92or3LPCpIqvd2PlWAAzisJTzVIQD2KCvUINBsbbmmh6+aMepSWhPXIAJxXEp5qkIB6FBXqEWg2NtzSQtfNGfUoLQnrkQE4ryQ81SAB9Sgq1CPQbGy4pYWumzPqUVoS1iMDcF5JeKpBAupRVKhHoNnYcEsLXTdn1KO0JKxHBuC8kvBUgwTUo6hQj0CzseGWFrpuzqhHaUlYjwzAeSXhqQYJqEdRoR6BZmPDLS103ZxRj9KSsB4ZgPNKwlMNElCPokI9As3Ghlta6Lo5ox6lJWE9MgDnlYSnGiSgHkWFegSajQ23tNB1c0Y9SkvCemQAzisJTzVIQD2KCvUINBsbbmmh6+aMepSWhPXIAJxXEp5qkIB6FBXqEWg2NtzSQtfNGfUoLQnrkQE4ryQ81SAB9Sgq1CPQbGy4pYWumzPqUVoS1iMDcF5JeKpBAupRVKhHoNnYcEsLXTdn1KO0JKxHBuC8kvBUgwTUo6hQj0CzseGWFrpuzqhHaUlYjwzAeSXhqQYJqEdRoR6BZmPDLS103ZxRj9KSsB4ZgPNKwlMNElCPokI9As3Ghlta6Lo5ox6lJWE9MgDnlYSnGiSgHkWl8fV49OjRlStXbty40b4AUZw4ceLMmTP2KiJiwy0tje+6KEA9SkvCeqzrALzrK19vhY1fefWDn3/49Tf+m/uF/eTFV49cODKiv8sfPfiQWr/7/gdbrdZ7L738Px75qftVopLwVIME1KOoiK3HpaWlG2+8seNedMzMzNhf5pAwAD/++OPqBu/bt8++rNEWFhZardaKFStOnTplXzYAi4uLq1evjvbt6qKqDfeBr3553aWXqDN5dM27dv3R1v/+H77353/84Mtz/9o92M3fP/udlf/LBW8X76d+37z0jQN/ccMH16mLxi5eU/I6Vf7Hy8+sXvWO7+6adi+SGbFdFxFQj9KSsB7rOgCrmNtutf39D68fu+OT96iV84eG/vrggvtV/eTFV4/843/yLvM7mrtwvQUXm4SnGiSgHkVFbD0uLS1NT0+vf8u6def+MdYr69evn5ubs7/MkXwANif5hDdjoNTPODQ09Morr5jragAeHx+P8yQwA7BXJRvu6a2/12q1Hrpr83//D99T++Ptm36r1WoNnX9e+c3x3z/7ndWr3qFqwdxwq724uqodv39z+5wZvVh9ozL51syn28X1T9e7F1n5m2//qXdfHlofUMR2XURAPeqE6i60PqAkrMd6D8Deze6PTvz8+ht+Uy3+wi+uqPZZoL/76Wlrw80zTqgR6lFU6lKPao7tYZRKPgCrG3DDDTc0eDYLDcCRMQB79b/h/ptv/6l3E/ytmU8va8OtnhpS3dLccKtNtroqtbO3no8qyP/8T9+/8bqry2z9Q09MhdYHl7p0XQwC9agSqrvQ+uCSsB4bOABbz0R95Rtz7hf2HO+Gu0ZJeKpBAupRVOpSj/UdgNXrn/ft27djx46mvgqaAViy/jfcoWeB/ud/+v4tH762eJtrxrvh1jvmVqvVw65XDQPWdbrR38X6FqH1gaYuXReDQD0W1F1ofaBJWI/NHICfeHZenwTVbovZcKPWqEdRqUs9FgzA8/PzN9xwg75/JyYmDh8+rC91B+CFhQXrqubn5ycnJ9WXDw0N7d692/wu6hpmZmaOHz++fft2ddjY2FiZYU9NhmokK3g98NLSkr5mk3mzi4/RN/Lo0aPqZxkfH9dzYPEP2PXK1WdZTU9Pr1y5Uq1PTEzoH18N9hY157u/fKX4Luv5d951AC74KdTjFO67yq314t9k8b2QSp8bbnND7O5oy7/nMLThNhd72PWqYUBxRwKVNw78xeT/foX7LULrg05dui4GgXoM1V1ofdBJWI/NHIBDzzjtffKZy3/9/Wr9vZdePvvnT7nXWXyMteH2fgyPtfiVb8y9+OqRD1xznfdlmQuHfnzHJ+8xj9cGsaFPeKpBAuqReuxBaADWny+1efPmbdu26eFEP9FqzWBqCjWfq1TXMDQ0pK5BTUfmN1LXsHnz5pUrVw4NDW3btk0Nb2We8FTfTn330NOkamxT89i2bdvUu53VN9q/f3/JY8wb2Wq11q1bp+fArj9g1yt/+eWX1VepA6wff35+Xl+t+hb33nuvGmi9A3DXu6zn33nxAFz8U3hPMOsu6/qbLLgXEupzw21tascuXvP0n37BPUan4ONz3A239Uk83j19Qf7+2e98+APv/9TvfEx/ubtv/ptv/6n1LdTW/MBXv+xd/7+f+rq5/t1d03//7HfUvnzs4jX/Zf5J92YsN3XpuhgE6tFbd3nWYwMH4NB7DtUu/Bd+ccWBhb9dOPRjtW+2NrVdj3GfcXI/hse6YZ/eOWPupy+7Yq3+OFx9mFq0/tf9eftPwlMNElCP1GMPvPOJ/pBh8/nDgwcPmp88bM5g6r/NIcq92qWlJeu1yuoYNcfqw9Qs5D63admxY4c7bFtPM1qL3jm56zH6Rlq/ojI/YNcrX1hYuP32281fsvXju1+iuANwmbus59958QBc/FPozyoz53Dz8Ysyv8nQvZBW/xtud1sc2narF0Cu+IXh1//qG2p7PXT+eXoT7G64+3zG6Vszn5751O+bN8/70TuhbxFaN6/wS/fcaf7soSe1lpW6dF0MAvUY+hah9QbXY9MGYPNTZ9976eX6U2f1kXpPrJ+V0k9JlTnG3XC7K9YNUx9+q18Fqj8L1xwM1PW7K5Un4akGCahH6rEH7vihX3zrvqvWXNczmDv9hq7BGtu839q7aFHzmPsMoftTeMdd81Z1PUZdszv7lfkBu165y7qG8gOw9/a4695flHfRVDwAu6yb5w7Y5q3y3nLvqVL+BsTR/4Y79LzN7b/5z8zdp96n6s20+jxYvUmtdsP9P15+5n3/2+r/Mv+k+aLQFb8w7D4pFPoWoXVzw60+y0e/s7HrR/uUSV26LgaBegx9i9B6g+uxOQOwdv7Q0FXrr53986fMJ222/uEfqUv1nljvgD/yGzeWP8bdXrsr3klAr+gNt3mM3l67t6HaJDzVIAH1SD32wB1+QkOX9ZSm+sLR0VE1mZgH6yf91CtatS1btphP4rlTnHe4dannD83ne71PM5aZP7se472RJX/ArleunDhx4plnnjGvYbkDcOgw91lo74/T9XdeZgAu+CmsLzf/t+Rv0nuzk6tkw229Q08zN7hqe21uXtWK3qRWu+H+m2//6dbfusH61t4XbYa+RWjd3HBbLw2t+4YbyVGPoW8RWm9wPTZnAC7YoZp7Yr211Ztp9bLMMsd4t9fuinczzYYbElCP1GMP3AG4YNoxn8pTX/jxj39cDTDecdSreKrpOozp5wzVO0419ZZX89q6vgK5zDHeG1nyB+x65V0/Isv9EsW6VSXvMvcLla6/84LrL/NTWE/zuu/ftr/yLcWnSnJVbbhV/t03dlvbbvUqR/NpH5fazla74Z7e+nt672tukd1XRYa+RWjdvDa13pgNN5KjHkPfIrTe4HpkAE624fa+wFJtuPUxlSfhqQYJqEfqsQfuABwaurzPAG/cuFF/1JN+YrPgGkzeqabrMKa+St2bLu/7Xc3PoLK+XddjvDdyWT9gwZWrsXB8fFy/gdb6dqFvVPIwdwj3/jhdf+fFA3DXn8Iaes1huOCWm9wrlKD/Dfc3P/+AtYX9d9/Yrbek6kmn4g+nVSm/4Tb/mIpm7Yk//IH3m7dKfzKQuyf2fouC9QZvuJEc9ej9FgXrDa5HBuBkG25z0frQHX0DKk/CUw0SUI/UYw/cATj0tkz9ZJ1aN2cS9yOgvddg8U41XYcxa6LTrJunJ6stW7aoKdT94zpljvHeyDI/YNcr985+JSdb91Z5b4/1O/F+YZnfecEA7L2F7nfR1/DGG29Y38t7yy3uFUrQ/4bbfG5HR+9W1R7U3HB7P/mm2g23+RpLl3UDvN+iYL3BG24kRz16v0XBeoPrMYsB2PtSRv2BOgXvOXSPcbfX7kr5Dbd63kl/31arddX6aw8s/K17+6tKwlMNElCP1GMPvANwwUcKh16VquZSfWnob/POz88XPE/YdRjzjlua+XJfdT1jY2PuzKaVOcZ7I8v8gF2v3P1Z9Kcfd51s3VtV5i7zfmHX3/lyB2DvT6HvnfXr11uPX3T9TYZudnL9b7h3/P7N3j20epJHv+0w9JzP33z7T6t9z6H+uB1rUV+P9dE7oW8RWm/whhvJUY+hbxFab3A95jIA6+eO3M20+/xSwTHu9tpdKb/h/tGJn999/4PFt7zaJDzVIAH1SD32wDsA67nL+qOyxW+OtcYefQ3qBcDqY436fDYydGsV9bX6Ri4sLFgvll6/fr31B3u6HuO9kUrXH7DrlauZUP39W/1EsTU66mPUn9h1n37Xut5loS8s/p3rA1qt1ujo6HrD1q1bz5w5U+an0N/avUllfpPem51cJRtu7wsprXXzaaKxi9e8/lffUC/O1B+NU9WGW/21Fe+6vgHmAdb3/ftnv/Mnn/6DgvUGb7iRHPUYqrvQeoPrsd4DsN4Ql/lbnXff/6D7N0Vv/cSdyzrG/Suj7op3w/3Es/N6w6237+r2s+FGNNQj9diDgpHy4MGD6m2ramixRkd3JllcXFRD19zcnPcaJiYmXnvttYJr6DqMhV7/rKlRSh2g/ntsbEx/UJa6Me5LtQuO8d5IrfgH7HrlZ8+enZub0xPjxMTEq6++unr1auvbTU9PqwP0p22HblXxXRb6wuLfuTkAW/SXlPkp9Ouxvd+o+DfpvdnJVbXhbrVaW3/rhqPP/bn6iJ1//S/+UL248b/73vinmU/+/P2z3ynecHu30Wb09/UeaV5Vq9X68z9+UF9k3jBz0+xddzfc+q/OmH9GtefUpetiEKjHUN2F1htcj3UdgM2ttql42733yWcu//X3qyN/7ZL3PvrVx5d1jLmN1gdYKx/5jRvdwz69c8ZcUU86mR+6Y1F/Nsa9bf0n4akGCahH6hGa+alLJnOELnNMzwZ65TXlfTl3ffW/4f7Cttte/6tv/M//9P2vfXa73omOrnmXuaPVOfDVL6+79BJ1jPmHSc1drLLxn673LrrXqeJ+sK3e+7oXKfra9AFjF68xnzJy192b9KV77jRX+n/Sia6bM+rRW3ehdfcmNake6zoANyPmuw1dg/jonYSnGiSgHgtCPeZGzZ9bt241F/XbU9UMVuaYng30yuuo4I3ENdX/hptUG7puzqhHaUlYjwzAKaPec2hvtN8yiJdiJjzVIAH1WBDqMTf6Vbvq3bPqnaXqZbr6JbhljunZQK+8jqy/SNwAbLilha6bM+pRWhLWIwNwsqiXXKr3N1rrX/hX7XfPs+FG5ajHUKjHPJ04cWJ6elq/s1R9BtXc3Jw5fJY5pmcDvfJ6cT8sugHYcEsLXTdn1KO0JKxHBuBkUR9Xe/7Q0KNffdx8n+S//fevfeCa64rfPNlzEp5qkIB6DIV6BFA5NtzSQtfNGfUoLQnrkQE4ZRYO/fiue+4fv/Ltd6ufPzQ0uE/cYcMN6rEg1COAarHhlha6bs6oR2lJWI8MwHkl4akGCahHUaEegWZjwy0tdN2cUY/SkrAeGYDzSsJTDRJQj6JCPQLNxoZbWui6OaMepSVhPTIA55WEpxokoB5FhXoEmo0Nt7TQdXNGPUpLwnpkAM4rCU81SEA9igr1CDQbG25poevmjHqUloT1yACcVxKeapCAehQV6hFoNjbc0kLXzRn1KC0J65EBOK8kPNUgAfUoKtQj0GxsuKWFrpsz6lFaEtYjA3BeSXiqQQLqUVSoR6DZ2HBLC103Z9SjtCSsRwbgvJLwVIME1KOoUI9As7Hhlha6bs6oR2lJWI8MwHkl4akGCahHUaEegWZjwy0tdN2cUY/SkrAeGYDzSsJTDRJQj6JCPQLNxoZbWui6OaMepSVhPTIA55WEpxokoB5FhXoEmo0Nt7TQdXNGPUpLwnpkAM4rCU81SEA9igr1CDQbG25poevmjHqUloT1yACcVxKeapCAehQV6hFoNjbc0kLXzRn1KC0J65EBOK8kPNUgAfUoKtQj0GxsuKWFrpsz6lFaEtYjA3BeSXiqQQLqUVSoR6DZ2HBLC103Z9SjtCSsRwbgvJLwVIME1KOoUI9As7Hhlha6bs6oR2lJWI8MwHkl4akGCahHUaEegWZjwy0tdN2cUY/SkrAeGYDzSsJTDRJQj6JCPQLNxoZbWui6OaMepSVhPTIA55WEpxokUCcAERX7TgLQFKrG3W0fSRW6bs6oR2lJWI+RBmAiKvadhGy4JwNJHvtOAtAUbr0TCbHvJ+TBPROIhNj3UxQMwDnGvpOAurnjsSfveOxJexUAJHH//SUSYt9PyIN7JhAJse+nKAY+ADfD62+cvGjqSxdNfen1N07alwGIi3oEgGhouYAc1GMlGIBLueOxJ9XZxpNOQHLUIwBEQ8sF5KAeK8EA3J1+rIVHXIDkqEcAiIaWC8hBPVaFAbg7/VgLj7gAyVGPABANLReQg3qsCgNwF9ZjLSo84gIkQT0CQDS0XEAO6rFCDMBdWI+1qPCIC5AE9QgA0dByATmoxwoxAJelzjN7FUAK1CMAREPLBeSgHvvHAFwWZxsgB/UIANHQcgE5qMf+MQCXxdkGyEE9AkA0tFxADuqxfwzAZXG2AXJQjwAQDS0XkIN67B8DcFmcbYAc1CMAREPLBeSgHvvHAFwWZxsgB/UIANHQcgE5qMf+MQCXxdkGyEE9AkA0tFxADuqxfwzAZXG2AXJQjwAQDS0XkIN67B8DcFmcbYAc1CMAREPLBeSgHvvHAFwWZxsgB/UIANHQcgE5qMf+MQCXxdkGyEE9AkA0tFxADuqxfwzAZXG2AXJQjwAQDS0XkIN67B8DcFmcbYAc1CMAREPLBeSgHvvHAFwWZxsgB/UIANHQcgE5qMf+MQCXxdkGyEE9AkA0tFxADuqxfwzAZXG2AXJQjwAQDS0XkIN67B8DcFmcbYAc1CMAREPLBeSgHvvHAFwWZxsgB/UIANHQcgE5qMf+MQCXxdkGyEE9AkA0tFxADuqxfwzAZXG2AXJQjwAQDS0XkIN67B8DcFmcbYAc1CMAREPLBeSgHvvHAFwWZxsgB/UIANHQcgE5qMf+MQCXxdkGyEE9AkA0tFxADuqxfwzAZXG2AXJQjwAQDS0XkIN67B8DcFmcbYAc1CMAREPLBeSgHvvHAFwWZxsgB/UIANHQcgE5qMf+MQCXxdkGyEE9AkA0tFxADuqxfwzAZXG2AXJQjwAQDS0XkIN67B8DcFmcbYAc1CMAREPLBeSgHvvHAFwWZxsgB/UIANHQcgE5qMf+MQCXxdkGyEE9AkA0tFxADuqxfwzAZXG2AXJQjwAQDS0XkIN67B8DcFmcbYAc1CMAREPLBeSgHvvHAFwWZxsgB/UIANHQcgE5qMf+MQCXxdkGyEE9AkA0tFxADuqxfwzAZXG2AXJQjwAQDS0XkIN67B8DcFmcbYAc1CMAREPLBeSgHvvHAFwWZxsgB/UIANHQcgE5qMf+MQCXxdkGyEE9AkA0tFxADuqxfwzAZXG2AXJQjwAQDS0XkIN67B8DcFmcbYAc1CMAREPLBeSgHvvHAFwWZxsgB/UIANHQcgE5qMf+DXwA3nr5hc3ITR+8/KYPXu6u1zH2nYRsuCdDTUM9ApDPrfeapkktl66bLfdMqGmox/4xAOcY+05CNtyTgSSPfScBaAq33omE2PcT8uCeCURC7PspikgD8Nl/+DyRkISnGiSgHkWFegSajZYrLXTdnFGP0pKwHhmA80rCUw0SUI+iQj0CzUbLlRa6bs6oR2lJWI8MwHkl4akGCahHUaEegWaj5UoLXTdn1KO0JKxHBuC8kvBUgwTUo6hQj0Cz0XKlha6bM+pRWhLWIwNwXkl4qkEC6lFUqEeg2Wi50kLXzRn1KC0J65EBOK8kPNUgAfUoKtQj0Gy0XGmh6+aMepSWhPWYZgBWi0Ra7DsPjXPujqYe6xD7zgNQN+dqObDtI6Ji33lonHN3NPVYh9h3XtUYgMnbse88NM65O5p6rEPsOw9A3ZyrZTbcdYh956Fxzt3R1GMdYt95VUs5ALunIEmVOGcbkvOWnneRJAz1CDRDqLuG1kmS0HIzEaq70DpJkjj1yABM2olztiE5b+l5F0nCUI9AM4S6a2idJAktNxOhugutkySJU48MwKSdOGcbkvOWnneRJAz1CDRDqLuG1kmS0HIzEaq70DpJkjj1yABM2olztiE5b+l5F0nCUI9AM4S6a2idJAktNxOhugutkySJU48MwKSdOGcbkvOWnneRJAz1CDRDqLuG1kmS0HIzEaq70DpJkjj1yABM2olztiE5b+l5F0nCUI9AM4S6a2idJAktNxOhugutkySJU48MwKSdOGcbkvOWnneRJAz1CDRDqLuG1kmS0HIzEaq70DpJkjj1yABM2olztiE5b+l5F0nCUI9AM4S6a2idJAktNxOhugutkySJU48MwKSdOGcbkvOWnneRJAz1CDRDqLuG1kmS0HIzEaq70DpJkjj1yABM2olztiE5b+l5F0nCUI9AM4S6a2idJAktNxOhugutkySJU48MwKSdOGcbkvOWnneRJAz1CDRDqLuG1kmS0HIzEaq70DpJkjj1yABM2olztiE5b+l5F0nCUI9AM4S6a2idJAktNxOhugutkySJU48MwKSdOGcbkvOWnneRJAz1CDRDqLuG1kmS0HIzEaq70DpJkjj1yABM2olztiE5b+l5F0nCUI9AM4S6a2idJAktNxOhugutkySJU48MwKSdOGcbkvOWnneRJAz1CDRDqLuG1kmS0HIzEaq70DpJkjj1yABM2olztiE5b+l5F0nCUI9AM4S6a2idJAktNxOhugutkySJU48MwKSdOGcbkvOWnneRJAz1CDRDqLuG1kmS0HIzEaq70DpJkjj1yABM2olztiE5b+l5F0nCUI9AM4S6a2idJAktNxOhugutkySJU48MwKSdOGcbkvOWnneRJAz1CDRDqLuG1kmS0HIzEaq70DpJkjj1yABM2olztiE5b+l5F0nCUI9AM4S6a2idJAktNxOhugutkySJU48MwKSdOGcbkvOWnneRJAz1CDRDqLuG1kmS0HIzEaq70DpJkjj1yABM2olztiE5b+l5F0nCUI9AM4S6a2idJAktNxOhugutkySJU48MwKSdOGcbkvOWnneRJAz1CDRDqLuG1kmS0HIzEaq70DpJkjj1yABM2olztiE5b+l5F0nCUI9AM4S6a2idJAktNxOhugutkySJU48MwKSdOGcbkvOWnneRJEyT6vHEiRNnzpyxV/t29OjRlStXbty40b4AkCTUXUPrJEma1HJRIFR3oXWSJHHqsWYD8OOP3NgKG/21X7795isOP3+39VXT91zTarXGRt9x6j9/xr3Orle+8aPvdQ82c3DuE+vG3qkOHv21X979L//ZmSM75/7st1753l1n/+HzC381ZV+jz9D5/0gd794MfZGbowvbV144bB0/88B17pHFiXO2ITlv6XkXy8Q9V03Uo9LselxaWpqenl65cqX6YScmJvbv368vXVhYaLVaK1asOHXqVMeX9a2SAXhxcXH16tXW/TUxMXH48GH7ULz16xrEvdlgoe4aWi+O245MtFyl2S0X/QjVXWi9OO65aqIeFbH1WLMB+Ow/fH7pJw+ps8f8zR5/6f4bP/wevbjv/7hZH2/eH13vBuvKxy9/55kjO93DzKjjH7rvQ+rI4y/dv33qSvMUWfirqaHz/9Hcn/2WOt48mdTtXPrJQ3N/9lvmKbX0k4ce++IGfVjBLX/8kRvXr/snXQ/rmjhnG5Lzlp53sWSoRzO51aMeIEdHR7dt27Zlyxb1g+/bt08doAbg8fHxyp8ErnAAHhoa2rx587Y3rVu3zvoRcrC0tHTjjTcODQ298sor9mUGBuAehLpraL1raLlmcmu56FOo7kLrXUM9mqlXPdZvALYewNC/36WfPKRPuBW/eL75yErJh1sKrjwUdbB7Uj7+yI3m2WZej3u2qeiHZ/Q1b77pcl0n1k+ksvij6Y//s0v+1b+43nuFy0qcsw3JeUvPu1g+3pKhHnOox8cff7z9gLQxhR4/fvyWW26JMD1WOABbE536obIa8xiAByfUXUPrZeLtirTcHFou+hSqu9B6mXhLhnqUX4/NGYDP/sPnd3zy6v5/76Er90Z9R/dsW/rJQ7d87FLz7NEJnW1W1Dla/BOpY0peYXHinG1Izlt63sXyCZVM8dlbMqEr94Z6jElNTe0fc/DjrmtwA7B+Wrh4GmwSBuDBCXXX0HqZhLpicYMqmdCVe0PLRb2E6i60Xiahkik+e0smdOXeUI/LwgBsJ3TlbswHeNwjrYdPdEqeHOpMMm+MdU7rE7rkFRYnztmG5Lyl510sn1DJUI8FV1icutTjjh072r/tmRn7gre4Y6pamZmZOX78+Pbt29UvamxszBq9lpaW9KUmfVXuNZ89e3Z+fn5yclIdOTQ0tHv37uKXXnsnOu80WOaaDx48qF9BPTo6qo9RrwO3bqq6/eaLw/Vv5ujRo+p7jY+Pnzp1KrSuvqr4hpX5bas70eJ9UMP76zKdOHHCekO4/kbqeXX3VHHXS/5E3t+GQKHuGlovk1BXpOUWXGFx6tJy0adQ3YXWyyRUMtRjwRUWJ0491n4A1r9f877Xd4z1hmz3nHBT/myzzu+x0Xfs/+bvusdYKXlyqLPN/KGs950fXdi+9XfXlr/C4sQ525Cct/S8i+VDPWZbj2q0Gxoampubsy97kzumqpXNmzevXLlyaGho27ZtN9xwg7oSPSzptxZPTEzo9+Wqg/UnbLnXrEYp/YZeNYYVv/3YO9GpazYXy1yzGiOtY9QYuawBWP1mWq3WunXr1G0IrZe5YWV+2/Pz8/pr1fXce++93o8B8/66tJdfflldibrXrG/k/rzexxqW9RNZvw2ZQt01tF4mtNxsWy76FKq70HqZUI81rceGDMBH5v9Q3yu333yF+bDE0YXtq//xheqirmfPcs829xPPup5zJU8OdbZZx5sf/vb4IzeqLy95hcWJc7YhOW/peRfLh3rMuR6np6fVD6vGYGvadMdUtaIGQn2w9V5i61lBd0xyr9mdr5aWltRQ6n0yU3EnuuPHj6vnFfV3L3PNasQdGxszJ7H5+Xk1Ri5rAHZH6+L14htW5rcd+g273F+XaWFh4fbbbzcnZ/MbeV8wb/1mlvUTFT+0IUeou4bWy4SWm3PLRT9CdRdaLxPqsab1WPsB2DR0/j9Sn/dtHrz4o+nBnW3qeOuEc894MyVPDn22mbdfv+9cvddc/XfJKyxOnLMNyXlLz7tYPtRj5vVovWbVfDY4NAAXz3I7duywhjE1Spmzk3XN3lnX/e4W/VSzyfoRylyz9xhtWQOwO16G1r3f1Lph7nfxLlYyALusG+MO3taPUP4nKn8bkgt119B6mdByM2+56Fmo7kLrZUI91rQeaz8Aq9+v/qRvdc49+tBH9MGDPtvUd5+8+n/VX6V4PySt/MmhzzbrVQ1q0by05BUWJ87ZhuS8peddLB/qkXo8e/bskSNH9BhsPX3qDsDWNKgmq54HYP3sov5rRor6s0wFTxXqz7tSX6huv/kW2TLX3HV6XNYA7I7r3vUyNyz0tdZvu9oB+MSJE88884x5Y/R3t77c+t9+fiLJQt01tF4mtFxaLnoTqrvQeplQjzWtx4YMwCruvRLnbFOZ/+7t1jnn/XPVJU8O83wyX9Uwfvk7/9/D/8L8PLeSV1icOGcbkvOWnnexfKhH6lGz/oaQO664K+5IttyXQOvZyavrAGxOdAcPHjRvf5lrdq/EMtAB2Kt4XBzQANz1c8us53itX0s/P5Fkoe4aWi8TWi4tF70J1V1ovUyox5rWY6MGYHNdv+ncPdvMwzR9PWXONv1xav/n7o9bryuY/+7t+szwPuJS8uQwzzbzfeetVuuPPzP54Q+9W3/fkldYnDhnG5Lzlp53sXyoR+pR08+pmh99tNwBWB1jfQiWd4A0B+Cu85vLnej0GKbG7zLX3PWYwQ3ABd9U8X7tgAZgNdyOj4/rtwG73938VVgveC55G9zrFC7UXUPrZULLpeWiN6G6C62XCfVY03ps1ABsPixhvja92rNt6ScPbb7pcnXl0/dc436wuP6O1oekqZQ8Ocyzzb3N5heWvMLixDnbkJy39LyL5UM9Uo9a/wOwHoS2bNmixmD3b+G41+N9+2hX3olODWl6PixzzcXHuLOud9H7mylYL/6mivdrBzEAe6/B/e76Gt544w3rNvTzE0kW6q6h9TKh5dJy0ZtQ3YXWy4R6rGk9NnYALni4pThdz7ajC9v1ox07Pnm190UF6pUPVT3cYj3iYl1tySssTpyzDcl5S8+7WD7UY571ePTo0YmJCf13idQUpJ8GDL1g1V2xRjL139YnKrus67GmVk1/FLOXd6LTTwKbr9Qtvmb1mm3rmB/84AfqAOtBAfVZ0+rDt/oZgMvcMO/XugNwyeHT++tS3AFYnwzWd1e/q/Xr17cruvPPAvf8E0kW6q6h9TKh5ebZctG/UN2F1suEeqxpPTZqADZ/7/quqvZsU/e6PpXVWeUeFlovf3JYZ5v5haH14issTpyzDcl5S8+7WD7Uo3e9+AqLU4t6VKOI+klHR0fVSKOesNVTkDuuuCvuSLawsKCvWVm/fr31J3bc61Hjln7htPrwpOKhLjTRWZ9X3PWa9czs/TvA+hrUperLR0dH+3wGuMwN836tdwDWf4BX/Qlf7y9NfaG+u7WtW7eeOXPG/BO++tl7dwDWp433CefefiLJQt01tF4mtFzvevEVFqcWLRf9C9VdaL1MqEfvevEVFidOPdZvAF76yUPT91yjf7/qV28tqj/HrLKsP7plXc/Gj77XfD29/mg1/RCLfo/71t9de+yH29U1PPbFDe7X6us33xbvPUYfNn75Ow8/f7deVGVjvYbBei3+Q/d9yHuFXRPnbENy3tLzLpYM9ZhzPR4/fnz79u161BkaGlKzkD7AHVfcFXckU1PQ2NiY/ihg9Tbg4tFafYSVOlIdPDEx8dprr5kHWEIDsPucbddrXlpamp2dNR8RMF+2bV6qXtH9X//rf7WmUO9PVLCuFN8w79d6B2DzTzqvWLHCHU3NAdiir2pubk7/BiYmJl599dXVq1db310/WODeAKWHn0iyUHcNrXcNLTfnlos+heoutN411GN967FmA7D50IJr9Nd++fabrzDvIfevQntfHlDmyk36Sr5w/3WHn7976ScPzX75Y/objf7aL8/92W+Vv37rMRLrMP3Qjjq59f9a55mpa1G5iXO2ITlv6XkXyyR0SivUo0I9Lov3I6Pcj4ZGfZV5uXVjhLpraL04oa6l0HIVWi5CQnUXWi9O6JRWqEdFbD3WbAAmA0qcsw3JeUvPu0gSJud6VAPw1q1bzUX9htJMpqYGCz3r3lSh7hpaJ0mSc8vNSqjuQuskSeLUIwMwaSfO2YbkvKXnXSQJk3M96tfZqvejqjeCqhfWhl40ixqx3l/deKHuGlonSZJzy81KqO5C6yRJ4tQjAzBpJ87ZhuS8peddJAmTeT2eOHFienpavxFUfQjW3Nwc02/duR8W3Xih7hpaJ0mSecvNR6juQuskSeLUIwMwaSfO2YbkvKXnXSQJQz0CzRDqrqF1kiS03EyE6i60TpIkTj0yAJN24pxtSM5bet5FkjDUI9AMoe4aWidJQsvNRKjuQuskSeLUIwMwaSfO2YbkvKXnXSQJQz0CzRDqrqF1kiS03EyE6i60TpIkTj0yAJN24pxtSM5bet5FkjDUI9AMoe4aWidJQsvNRKjuQuskSeLUIwMwaSfO2YbkvKXnXSQJQz0CzRDqrqF1kiS03EyE6i60TpIkTj0yAJN24pxtSM5bet5FkjDUI9AMoe4aWidJQsvNRKjuQuskSeLUIwMwaSfO2YbkvKXnXSQJQz0CzRDqrqF1kiS03EyE6i60TpIkTj0yAJN24pxtSM5bet5FkjDUI9AMoe4aWidJQsvNRKjuQuskSeLUIwMwaSfO2YbkvKXnXSQJQz0CzRDqrqF1kiS03EyE6i60TpIkTj0yAJN24pxtSM5bet5FkjDUI9AMoe4aWidJQsvNRKjuQuskSeLUIwMwaSfO2YbkvKXnXSQJQz0CzRDqrqF1kiS03EyE6i60TpIkTj0yAJN24pxtSM5bet5FkjDUI9AMoe4aWidJQsvNRKjuQuskSeLUY6QB2Bv3ZyapEudsQ3JuGVKPAkM9As3gdlq6rsDQcjPh1iD1KDBx6pEBmLQT52xDcm4ZUo8CQz0CzeB2WrquwNByM+HWIPUoMHHqceADsBenmrTEOdsgE/UoLdQj0Gx0XVGh5WaOehSVOPXIAEzaiXO2QSbqUVqoR6DZ6LqiQsvNHPUoKnHqkQGYtBPnbINM1KO0UI9As9F1RYWWmznqUVTi1CMDMGknztkGmahHaaEegWaj64oKLTdz1KOoxKlHBmDSTpyzDTJRj9JCPQLNRtcVFVpu5qhHUYlTjwzApJ04Zxtkoh6lhXoEmo2uKyq03MxRj6ISpx5TDsBEWuz7CXlwzwQiIfb9BKAp3HonyWPfSciGezKQ5LHvpKoxAJO3Y99PyIN7JhAJse8nAE3h1jtJHvtOQjbck4Ekj30nVS3NAFxHdzz25B2PPWmvAkiBegSAaGi5gBzUY/8YgEt5/Y2TF0196aKpL73+xkn7MgBxUY8AEA0tF5CDeqwEA3Apdzz2pDrbeMQFSI56BIBoaLmAHNRjJRiAu9OPtfCIC5Ac9QgA0dByATmox6owAHenH2vhERcgOeoRAKKh5QJyUI9VYQDuwnqsRYVHXIAkqEcAiIaWC8hBPVaIAbgL67EWFR5xAZKgHgEgGlouIAf1WCEG4LLUeWavAkiBegSAaGi5gBzUY/8YgMvibAPkoB4BIBpaLiAH9dg/BuCyONsAOahHAIiGlgvIQT32jwG4LM42QA7qEQCioeUCclCP/WMALouzDZCDegSAaGi5gBzUY/8YgMvibAPkoB4BIBpaLiAH9dg/BuCyONsAOahHAIiGlgvIQT32jwG4LM42QA7qEQCioeUCclCP/WMALouzDZCDegSAaGi5gBzUY/8YgMvibAPkoB4BIBpaLiAH9dg/BuCyONsAOahHAIiGlgvIQT32jwG4LM42QA7qEQCioeUCclCP/WMALouzDZCDegSAaGi5gBzUY/8YgMvibAPkoB4BIBpaLiAH9dg/BuCyONsAOahHAIiGlgvIQT32jwG4LM42QA7qEQCioeUCclCP/WMALouzDZCDegSAaGi5gBzUY/8YgMvibAPkoB4BIBpaLiAH9dg/BuCyONsAOahHAIiGlgvIQT32jwG4LM42QA7qEQCioeUCclCP/WMALouzDZCDegSAaGi5gBzUY/8YgMvibAPkoB4BIBpaLiAH9dg/BuCyONsAOahHAIiGlgvIQT32jwG4LM42QA7qEQCioeUCclCP/WMALouzDZCDegSAaGi5gBzUY/8YgMvibAPkoB4BIBpaLiAH9dg/BuCyONsAOahHAIiGlgvIQT32jwG4LM42QA7qEQCioeUCclCP/WMALouzDZCDegSAaGi5gBzUY/8YgMvibAPkoB4BIBpaLiAH9dg/BuCyONsAOahHAIiGlgvIQT32jwG4LM42QA7qEQCioeUCclCP/WMALouzDZCDegSAaGi5gBzUY/8GPgBvvfzCZkSdbe56HWPfSciGezLUNNQjAPnceq9pmtRy6brZcs+EmoZ67B8DcI6x7yRkwz0ZSPLYdxKApnDrnUiIfT8hD+6ZQCTEvp+iiDQAn32xRSQk4akGCdQJ8LOnHiYSQj0CzcYWSFroujljCyQtCeuRATivJDzVIAHdX1SoR6DZ2AJJC103Z2yBpCVhPTIA55WEpxokoPuLCvUINBtbIGmh6+aMLZC0JKxHBuC8kvBUgwR0f1GhHoFmYwskLXTdnLEFkpaE9cgAnFcSnmqQgO4vKtQj0GxsgaSFrpsztkDSkrAeGYDzSsJTDRLQ/UWFegSajS2QtNB1c8YWSFoS1iMDcF5JeKpBArq/qFCPQLOxBZIWum7O2AJJS8J6ZADOKwlPNUhA9xcV6hFoNrZA0kLXzRlbIGlJWI8MwHkl4akGCej+okI9As3GFkha6Lo5YwskLQnrkQE4ryQ81SAB3V9UqEeg2dgCSQtdN2dsgaQlYT0yAOeVhKcaJKD7iwr1CDQbWyBpoevmjC2QtCSsRwbgvJLwVIMEdH9RoR6BZmMLJC103ZyxBZKWhPXIAJxXEp5qkIDuLyrUI9BsbIGkha6bM7ZA0pKwHhmA80rCUw0S0P1FhXoEmo0tkLTQdXPGFkhaEtYjA3BeSXiqQQK6v6hQj0CzsQWSFrpuztgCSUvCemQAzisJTzVIQPcXFeoRaDa2QNJC180ZWyBpSViPDMB5JeGpBgno/qJCPQLNxhZIWui6OWMLJC0J65EBOK8kPNUgAd1fVKhHoNnYAkkLXTdnbIGkJWE9MgDnlYSnGiSg+4sK9Qg0G1sgaaHr5owtkLQkrEcG4LyS8FSDBHR/UaEegWZjCyQtdN2csQWSloT1yACcVxKeapCA7i8q1CPQbGyBpIWumzO2QNKSsB4ZgPNKwlMNEtD9RYV6BJqNLZC00HVzxhZIWhLWIwNwXol8qi0uLr5QyDr+yJEj9hEvvHDy5EnrsEE4ffr0rl27ZmZmXnrpJb146NCh0I0puEgyur+oRK5HAJGxBZKW5Xbdl156yfq3Xjty5Ih9dFLuDurYsWP2QT156aWXarHD6YotkLQstx4rxADckQOPtCbXtlb9Ustrzar2pRs/1JqZah36lv21tUjkU+306dObNm2yf4+t1sjIyM6dO2dmZqzj9+/f/8ADD6xatUofefXVVx86dMg6bBCuvvpq/U31vxl79uxZs2aNXm+1Wnv37u16kWS16P4//ubOay9796+MXGD+erX3/OpFt1xzxc+eeviLn/jotZe92774TcPnn3ftZe+evedm98pFJXI9AoisXlugk0+3Nzmjq+2Oqoxc0L50cm17C7TvC/bX1iXL7bp79uy5++67zW2J1+Tk5K5du+JsV0L27ds3Ojpq3ip3l9WbjRs37tmzx16toVpsgX721MO3XHPFFWvead6V2q+MXHDtZe/+4SP3/vCRe6+97N0Xrhi2j3jTFWveec9vrnevWVqWW48VYgD2ZPH51tXv6ziTpja02/3MVHsG1ibXtl76mv21wpPkVHvppZfMX2ar1dq5c6d9kOH06dPDw+2SfuCBB+zLBuPkyZOhm3fs2DHzInPKLbhIrLp0f5UdG68zf8OtVuvb9/+udczhr37GGpXf86sX/XTv59xrE5gk9Zibo0ePrly5cuPGjfYFFVHXPz4+fubMGfuyt3iPOXHiRMGXoBnquAU6+2Jr5yfMntpae3H76YGZqdaGq95eXLOqtXen/YXy01vXtf65Vw+UqxeCzc7OmmPn1NTU6dOn7a+PZXFxUW2flEoG4EOHDrVarVWrVi0uLtqXFZqcnLSXOnU9oHL12gI9/dk79V2pqEf/rdxyzRXWYfNf/pR7mMz0Vo+VYAD2Z899HSfTzNS59cXnO/4BGLmgdewJ+2slJ9WptnHjRvP32XUzumrVqrVr19qrA6NHbmX//v3mpeYtt6bcgotkqlf3/+Ej95q/4Var5R7zs6cevm1y3DymFo96qqSqR2kWFxdXr/Y/67Rv3z776GWSOQAvLCy0Wq0VK1acOnXKPrpS6ncb4RvBq6ZboEPf6ijDybVvXzQz1XHR7A77a4Wn565rPQlsvrr49OnTGzZs0BetWrXKfC9VZOZr0yoZgPXr+JbVjXft2tVqFY0YXQ8YhHptgX721MPWE7zfffA295jZe242j1l90Ur3GLHpuR77N/CTr6bdf+9O83R6ewB2/2EYXW1/reSkOtXcJ4EL3k+iHmq1ptBBm52dVf+8bdq0yXqY07zZDMAxc/irnzF/w8Pnn+ce4w7A07de7x4jM6nqURo1pA0NDW3evHlbp8OHD9tHL5PkAbj4qyrBAJxWTbdAx54we2rHALz4fPsJYW14qGbvCOu561pverLeXnv69GnzgJGRkaref7tc1Q7AJ0+e1E8PlH9a4tChQ+qr7Ave0vWAAanXFuhnTz28+qKV+t5stVrfn7nLPcYagN/zqxe5x4hNz/XYv4GffDXt/gUD8NkX7TcJH5mzv1xsEp5qa9euNX9pBa+C3rlzZ/k+Wy3vWG7ebAbgmLEG4NDjmgzAdTfQIU3mABzNQH+36KqmW6CCAfjsi627b+q4dM999pdLTs9dt3gAVm/BNQ9Yu3btcl8zXIlqB+AHHnjA/KHKPLN9+vRp/Zpw+7I3dT1gcOq1BeptAL72sne7x4hNz/XYv4GffDXt/sUDsPUO4Rp9GkTCU23//v3mLy30fpLFxcVVq1ZFfvq3mHmzGYBjhgE4EwMd0hiAB/e7RVc13QIVD8DWq6A3fsj+csnpuet2HYCt99/GfyGbUuEAvLi4ODIyYv5EXRvpsWPHzBtgX1zigIGq1xaIAXigBn7y1bT7Fw/A5ut/2j3uYfvLxSbhqaYmW/P35p0Y9+zZ433698CBAw888MDk5OTIyMjw8LD6xEXroyYOHTo000n98/PSSy9NTU2tWbNmeHh406ZN1tO8e/futb7K+iDHgttccJFS5mbHVK/uzwCciTJDmpohZ2Zmjh8/vn37dnVfj42NqddIHz9+fHJyUi3efvvt5pypB+ClpSX9haOjo3Nzcx3f4E3z8/P6eoaGhnbv3m2NrEtLS7OzsytXtjclQ0NDDz300Ouvv24Nt2WOscby0E/3yiuvvP2932T+FKbQxrTr7/bEiRPT09Pq1rZarYmJCf1NH3/8ce8e2l0v/r3pn+7o0aPqsPHx8dDtaZiaboGWNQBvut7+csnpuet2HYDNt8sq+kOeQpuT06dPW+uhD1t+4YUXdu7cOTk5qfZRk5OTO3fu9L5mrcIB2P1rF6EfXDl06JA1MOufS/3Zy64HuPsx9e1mZ2c3bNgwPDy8Zs2aXbt22d+4tHptgRiAB4oB2J/iAdj6+yw1+hyshKea/swDzTvorl27dnZ21lw5efKkanyqRc7OzuoGumbNGqsXv/DCC+ZDsFNTU7Ozs9aDstb3XVxctF7kU37KLbhoWTc7mnp1fwbgTHQd0vQQtXnz5pUrVw4NDW3btk2NUitWrPiTP/kTNdNu27Zt3bp11ntr1ReOjo6qL9y8efOWLVvUqWLtDtVcp9+KrGZC62nbHTt2qGO2bdt2ww036LPOPKzMMd4B2Pzp1BcODQ2ZM7D+tLCJiQn9w6rjQ881Ff9uX375ZfVjqiu0vqn3ieulpaUbb7zRvGFdf2/mT9dqtdatWxe6Pc1T0y1Q8QA89fbnPbXt2mZ/ueT03HXLDMDWJsf8uJO9e/ea61NTU2r9hRdeMK95zZo1Hdf45pA8NdV+yGHnzp0HDhzYu3evPn5kZMT9w0tVDcDqSYvZ2Vnr/WuhP89x5MgRa69lmpmZ6XqA2jhZDyLs37/f+hTV9qvuAw8TdFWvLRAD8EAxAPtTMADvf7jjokxe/FMJ89MUFOv9JPv377deGn3y5En1eOfo6KhenJ2dffv37zzvYf5F35GRkTVr1uzdu/fAgQPm445W91xcXNQXuaNsDxf1cLPjqFf3ZwDOROhDsJ599ll9jBqiVO2oyUpNYupO1/s8fVV6PHO/0PshzO6wt7S0pEZZ/dmn7lcdP35cTaT6C8scExqArRupBkuzV1hPvbqzqKt4AF5YWLj99tvNTxozv6n+DZuf/qp+QOuWF//e9E+X5EXgadV0C1QwAJ98uuNjUFb9UvtjsdxrEJueu26ZAdiaclutlnpiUzE3J3oAVp97otetAVi/dG5kZERvjQ4cOKCPd59IqGoA1vsx6/1rw8PDBa9is34D9sUlDjhy5Ih5wMjIyKZNmw4cODAzM6MXh4eHvc9+d1WvLRAD8EB5Tr5q1bT7hwbgI3MdfyN+7cXtfwzcLxebhKeacvfdd5u/WGsO3LBhg/XiFrPl6ac4XnjhBb04PDxsHq/+spy+dGRk5MiRI2pdPYaqbNiwwfoqfVH5Kbfgoh5udhz16v7WAPwrIxd8f+YuNx9ee4l5GANw7YT+DJK5e3MHLe+IqBet6cv7NKZ5mDWzKdaYqo6x9pTW9Zc5xr1m9wDv4o4dO6xx1/phXcUDsMu6Ye5v2PpFlfm9qf8tfxuapKZboNAAfPq59oP+2sgFrZe+Zn+t8PTcdcsMwOZoqpgbA3NzYg7A5obBGoDNcVE/cG/9UWJrFKxqAF67dq36cvf9awVPwHadb7seYP10ZvMx1wuaXoF6bYHcAXj3nR9zt0A7Nl5nHsMAXJLn5KtWTbu/NQBPrj33J+CHh86tjFzQ/iDEej3w2U/rr4r6i+om3bvVx+Jbrdx8ZPTuu+9Wi+Yk6f471MO/MQWjbG8X9XCz46hX97cG4JIYgGunzJBmzVSKejbS+0pmvej9QmtS1fOw9RS0erG0GkFDT7eaY2qZY8wVa0S0bqT6tUQYgE+cOPHMM8+YP7K+JdaXW/9b5vcW+ukyUdMtkDUAr1nV3gJtur7jud8NV9XpT2Do9Nx1ywzA1r/y7deHG4/p97A5MV84ph+4t0ZE65ZUMgCrd5Pp/diePXvM77hq1Sr7C97Sdb7teoD105lPoff/o9VrC+QOwGUwAJfkOfmqVdPubw3Aa1a1Z+DJte1/AGam2q+Crt3oq5LwVNPMfwPM95NMTU257y05efKk+rj8VatW6fe6WA+yChyAe7jZcdSr+/MS6EyUGdK8Q1Q/A7B5mPlqalf54bbMMebKcgfgyl8CXeYjtczneK3XP5f5vYV+ukzUdAtkDcAjF5zbAm24qr0F2ruzZq99M9Nz1+1tADbfnN/D5mRxcVG9cHpkZOTAgQNq0XqR8CAG4I0bN+rH7r3vXwt96EDX+bbrAQzAZngJ9OB4Tr5q1bT7h14CXfckPNU0799DUu3V+y+KenJY/cexY8ceeOABqxELHICVZd3sOOrV/RmAM1E8pCneIaqfAdh9Brh4kgwdE3MAVodZH4Ll/mim4t+t+iWMj4/rtwG7t8Qceq0XPId+Xot7nfmo6RYo9BLoBqTnrltmAHbfA6zfhNXz5kRNvOoNwCdPnpyZmbE+SLnMAGw98WDybl1arZb18VrWZ4W67z1Wus63XQ9gADbDADw4npOvWjXt/gzAA2W9n2R2dnbnzp3F26OTJ0+qGXLDhg3Wn5sXOwAv62bHUa/uzwCcieIhTfEOUT0PwCXfA2zxHmMNt2WOcW+V90ZaA7CeNrds2aL/xpL7h5osBb9b7/jq3hJ9DW+88YY1kId+Xot7nfmo6RaIAdhVZgC2PgV6ZGTEvLS3zYmi/mDSyMjI1VdfXfxqMu+UuKwB+IEHHli7du0LnaxXQbsTstJ1vu16AAOwGQbgwfGcfNWqafdnAB4oq5OuXbvWfKmwa+/eveohT/VvRvGbaXv7N0Zf5P570NtFy73ZcdSr+zMAZ6JgSNO8Q1T5Adj6gOWDBw9aH0qsrsqa7tRfuNXPjrrH6CvXi2WOcX8c709nDcDqf8fGxgp+S66C3607AOsPcLZuifqVrl+/3v1tuz+vYv7evD9dJmq6BWIAdpUZgK2nSfXfAVZ625yo90+ppw02bNiwuLjYw3uAyw/A7qudQ7wV3XW+7XoAA7AZBuDB8Zx81app92cAHqjTp08X/21ek/5AKf0nhYonyd7+jdEXuf8e9HbRcm92HPXq/gzAmVBDmvtnkLZt22b9NaOeB+D169dbf2LXfd5SzX76Bcb6zwVbr/i1/sbv2NjY5OSk9Txt8THuj+P96dyXQC8sLKhZWlu/fr31d4ws6kpUI1pv2Lp165kzZ9TvSv95ZH3l1i3RM7z31c5df2/eny4TNd0CMQC7ygzA1p/Mtf7QY2+bE32p/ktIPQzAhw4dsp7R1dxPHg3tx6z3r7kfQF1mvu16AAOwGQbgwfGcfNWqafdnAB4064HS0AcqmA1Xf5pi8STZ278x+iJ3lO3hoh5udhz16v4MwJnQQ5qr+JXM5QfgmZmZ48eP6+YwNjbmDnLqmWH1xlo17E1MTLz22mvmAUtLS9PT0/qARx99VE285pha5pjeBmA1ao6NjekHCNSt9c6lSuh3q692bm5Oz70TExOvvvrq6tWrrVuip3r3mV6l+Pfm/ekyUdMtEAOwq+sAbM2H5vZD2bhxo/fSgs2JuW3Qn0rVwwBckvqLR+7L2TT16Z6a+8Gl1j7HurTMAQzAZhiAB8dz8lWrpt2fAXjQzL+H5I6jmjnN7ty5Uy1a/8wIHIB7uNlx1Kv7u38H2D2GARiZsD6BWbMG/gEp815fuGq6BbIG4LUX2wfUNz13XWsAdt+0ZT79OzIy4j47OjU1pQ/YtGmTd93anJgzs/4S689JWreknylxz549w8PD6nlmL+v9a+6fruz6QH/XAxiAzfQwAF95ybvcY8Sm53rsHwOwPwzAEWzYsEH9egv+qLr5cVkjIyMPvMl6+fSRI0fMHtr/ADw7O9vnRT3c7Djq1f3dvwPsHsMAjEyoAXjr1q3mon7X7kBH04I3EqNYTbdA7t8Bdo+paXruutaHd5qDmfWitquvvtqdfq3pcXR0VM2Z1kuCrc2J+Yzr8PDw3XffvXPnTutToA8cOGDuJcwpUT/+XsbJkydXrVp19dVX2xcYFhcXrZ2M9SSwNb6q4XzPnj36VX7LPYAB2PxtlBmAQ6+Vk5me67F/DMD+3H2TeTq1Nn7IPqCmSXiqudQzourPINmXvcV8+FPZsGHDsWPHzH+KRkdHzUHXbJFmK9fztvqH5PTp0/oi66/qmX/+rreLerjZcdSr+3/7/t/t+CW2Woe/+hn3sCsveZd5zMevvNQ9RmZE1SOE0y9mVu8uVu+2dT9eaxDUk8zuk8/oqqZboP0Pmz21NTzUWnzePqam6a3rWk+6qofX1Xto9+zZox92X7VqVcFgpiZMfQ1r3zQyMmJuGKzNifVmMbWrOXLkiPls85o1a9SHY7kfsLJhw4aOWxB27Ngx9VMU/EFKxXogYHh42HoK2npCe9OmTdZWp/gA6yli/dTCyZMnzXXzKfTy6rUF+vE3O5+La7V23/kx97AvfuKj5jHD55936i+/6B4mM73VYyUYgDty8unWgUdaD9xinkvnTG1o/5NQ3z/+rpLwVPNas2ZN8SOUx44d04+Arl27Vr/MWH/AsvkA5KFDh6wXKemPYXQ/AnHVqlXqAyp27dplPZ6q/tk4ffq096LJycnii5Z7s2OqRfc/9ZdffPqzd07fev2FK+zPorxizTunb71+/suf+tlTD7+65/49f3CT9fSvctvk+Ow9N3unZVGRVo8Q7sSJE9PT0/rdtupDsObm5gY6/bofFo3y6rUFWny+9cJXWru2tUYu6Oio6m3Ae3e2Dn3L/pLaZbldd8+ePRs2bHD/uTetWrXq7rvvtp4T9jpw4IB5VaOjo4cOHTJfnqYW9VWdPn366quv1uv6I0X27t2rB9FNmzbpJ5Ot6VQNzMUDrfvC5lWrVm3cuNH6cQ4dOjQ1NaVvjMUcR0+fPj01NaV+zFWrVk1NTVlPchQcsGvXLusZ5uHh4dnZ2Zdeesn90awP2S6jFlugnz318PyXP/XFT3z0ijXvtH7k4fPP27Hxuu8+eNtP937up3s/990Hb9ux8brh88+zDrv2snd/8RMf/eEj97rXLC3LrccKMQB35OTT7e5fEAbgah04cMD7SiHLSy+95D3M+ohFaQTe7Fp0/1N/+cXvz9xVED0AuxeZYQAGkFa9tkBqAC5IhgPwIOzfv392dvbIkSP2BQGHDh3yDrGHDh0qeAFdcl23Ol0PqFwttkBqAHa3NGbUAOyum2EALsYAnFcSnmqQoC7dP5NQj0CzsQWSFrpuztgCSUvCemQAzisJTzVIQPcXFeoRaDa2QNJC180ZWyBpSViPDMB5JeGpBgno/qJCPQLNxhZIWui6OWMLJC0J65EBOK8kPNUgAd1fVKhHoNnYAkkLXTdnbIGkJWE9MgDnlYSnGiSg+4sK9Qg0G1sgaaHr5owtkLQkrEcG4LyS8FSDBHR/UaEegWZjCyQtdN2csQWSloT1yACcVxKeapCA7i8q1CPQbGyBpIWumzO2QNKSsB4ZgPNKwlMNEtD9RYV6BJqNLZC00HVzxhZIWhLWIwNwXkl4qkECur+oUI9As7EFkha6bs7YAklLwnpkAM4rCU81SED3FxXqEWg2tkDSQtfNGVsgaUlYjwzAeSXhqQYJ6P6iQj0CzcYWSFroujljCyQtCeuRATivJDzVIAHdX1SoR6DZ2AJJC103Z2yBpCVhPTIA55WEpxokoPuLCvUINBtbIGmh6+aMLZC0JKxHBuC8kvBUgwR0f1GhHoFmYwskLXTdnLEFkpaE9cgAnFcSnmqQgO4vKtQj0GxsgaSFrpsztkDSkrAeGYDzSsJTDRLQ/UWFegSajS2QtNB1c8YWSFoS1iMDcF5JeKpBArq/qFCPQLOxBZIWum7O2AJJS8J6ZADOKwlPNUhA9xcV6hFoNrZA0kLXzRlbIGlJWI8MwHkl4akGCej+okI9As3GFkha6Lo5YwskLQnrMdIATETFvpOQDfdkIMlj30kAmsKtdyIh9v2EPLhnApEQ+36KggE4x9h3ErLhngwkeew7CUBTuPVOJMS+n5AH90wgEmLfT1EMfAAGAAAAAEACBmAAAAAAQBYYgAEAAAAAWWAABgAAAABkgQEYAAAAAJAFBmAAAAAAQBYYgAEAAAAAWWAABgAAAABkgQEYAAAAAJAFBmAAAAAAQBYYgAEAAAAAWWAABgAAAABkgQEYAAAAAJAFBmAAAAAAQBYYgAEAAAAAWWAABgAAAABkgQEYAAAAAJAFBmAAAAAAQBYYgAEAAAAAWWAABgAAAABkgQEYAAAAAJAFBmAAAAAAQBYYgAEAAAAAWWAABgAAAABkgQEYAAAAAJAFBmAAAAAAQBYYgAEAAAAAWWAABgAAAABkgQEYAAAAAJAFBmAAAAAAQBYYgAEAAAAAWWAABgAAAABkgQEYAAAAAJAFBmAAAAAAQBb+fxy8fV224ScwAAAAAElFTkSuQmCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6msx2of6C8_U"
   },
   "source": [
    "### 4.2.1 Ablation models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EpfSVQlUP9t"
   },
   "source": [
    "#### The vanilla NLI model without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HoCjPNp8C-b4"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Vanilla_NLI_Model(nn.Module):\n",
    "  def __init__(self, shared):\n",
    "    super().__init__()\n",
    "\n",
    "    # Embedding layer\n",
    "    self.prem_embedding = nn.Embedding(shared.vocab_size, shared.embed_dim, padding_idx=shared.pad_idx) # discard <PAD>\n",
    "    self.hypo_embedding = nn.Embedding(shared.vocab_size, shared.embed_dim, padding_idx=shared.pad_idx) # discard <PAD>\n",
    "\n",
    "    # Encoding Layer\n",
    "    self.encoder = nn.LSTM(\n",
    "      input_size=shared.embed_dim,\n",
    "      hidden_size=shared.hidden_dim,\n",
    "      num_layers=shared.num_layers,                  # single recurrent layer\n",
    "      dropout=shared.dropout if shared.num_layers > 1 else 0.0, # disabledï¼Œ dropout only applies between recurrent layers\n",
    "      bidirectional=True,                       # Bi-LSTM\n",
    "      batch_first=True                        # (B, T, E)\n",
    "    )\n",
    "\n",
    "    # Regularization to prevent overfitting\n",
    "    self.dropout_encoder = nn.Dropout(shared.dropout)\n",
    "\n",
    "    # Classification layer\n",
    "    feat_dim = 2 * (2 * shared.hidden_dim)            # (prem + hypo) Ã— BiLSTM(2H each) = 4H\n",
    "    self.classifier = nn.Linear(feat_dim, shared.num_classes)    # simplest linear classifier\n",
    "\n",
    "  def forward(self, prem_ids, hypo_ids):\n",
    "    # Encode premise\n",
    "    prem_embed = self.prem_embedding(prem_ids)            # (B, T_p, E)\n",
    "    _, (prem_h, _) = self.encoder(prem_embed)           # return encoder_output, (prem_hidden_state, prem_cell_state)\n",
    "    # Token Aggregation: concat two-direction final hidden states\n",
    "    prem_vec = torch.cat([prem_h[-2], prem_h[-1]], dim=1)     # (B, 2H)\n",
    "    prem_vec = self.dropout_encoder(prem_vec)            # apply dropout to concatenated premise hidden state\n",
    "\n",
    "    # Encode hypothesis\n",
    "    hypo_embed = self.hypo_embedding(hypo_ids)            # (B, T_h, E)\n",
    "    _, (hypo_h, _) = self.encoder(hypo_embed)           # return encoder_output, (hypo_hidden_state, hypo_cell_state)\n",
    "    # Token Aggregation: concat two-direction final hidden states\n",
    "    hypo_vec = torch.cat([hypo_h[-2], hypo_h[-1]], dim=1)     # (B, 2H)\n",
    "    hypo_vec = self.dropout_encoder(hypo_vec)            # apply dropout to concatenated hypothesis hidden state\n",
    "\n",
    "    # Sentence Aggregation: combine premise and hypothesis as unified input for classifier\n",
    "    combined = torch.cat([prem_vec, hypo_vec], dim=1)       # (B, 4H)\n",
    "    combined = self.dropout_encoder(combined)            # apply dropout to combined premise-hypothesis representation\n",
    "\n",
    "    # Classification\n",
    "    logits = self.classifier(combined)                # (B, shared.num_classes)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxigZqnfUUYI"
   },
   "source": [
    "#### The vanilla NLI model with dual-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQf_OFHJUUuO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DualAttn_NLI_Model(Vanilla_NLI_Model):                # inherit vanilla NLI\n",
    "  def __init__(self, shared):\n",
    "    super().__init__(shared)\n",
    "\n",
    "    self.self_attn = nn.Linear(2 * shared.hidden_dim, 1, bias=False)\n",
    "    self.cross_attn = nn.Linear(2 * shared.hidden_dim, 2 * shared.hidden_dim, bias=False)\n",
    "\n",
    "  def apply_self_attention(self, encoder_outputs):\n",
    "    attn_scores = self.self_attn(encoder_outputs)            # (B, T, 1)\n",
    "    attn_weights = torch.softmax(attn_scores, dim=1)          # (B, T, 1)\n",
    "    attended_vec = torch.sum(attn_weights * encoder_outputs, dim=1) # (B, 2H)\n",
    "    return attended_vec\n",
    "\n",
    "  def apply_cross_attention(self, src_vec, tar_vec):\n",
    "    attn_scores = torch.bmm(src_vec.unsqueeze(1), tar_vec.unsqueeze(2)) # (B, 1, 1)\n",
    "    attn_weights = torch.sigmoid(attn_scores)              # (B, 1, 1)\n",
    "    context = attn_weights.squeeze(2) * tar_vec            # (B, 2H)\n",
    "    return src_vec + context                      # (B, 2H) residual fusion\n",
    "\n",
    "  def forward(self, prem_ids, hypo_ids):\n",
    "    # Encode premise\n",
    "    prem_embed = self.prem_embedding(prem_ids)            # (B, T_p, E)\n",
    "    prem_out, _ = self.encoder(prem_embed)             # return encoder_output, (prem_hidden_state, prem_cell_state)\n",
    "    # Self-attention layer\n",
    "    prem_self = self.apply_self_attention(prem_out)         # (B, 2H)\n",
    "    prem_self = self.dropout_encoder(prem_self)           # apply dropout to attended premise hidden state\n",
    "\n",
    "    # Encode hypothesis\n",
    "    hypo_embed = self.hypo_embedding(hypo_ids)            # (B, T_h, E)\n",
    "    hypo_out, _ = self.encoder(hypo_embed)             # return encoder_output, (hypo_hidden_state, hypo_cell_state)\n",
    "    # Self-attention layer\n",
    "    hypo_self = self.apply_self_attention(hypo_out)         # (B, 2H)\n",
    "    hypo_self = self.dropout_encoder(hypo_self)           # apply dropout to attended hypothesis hidden state\n",
    "\n",
    "    # Cross-attention layer\n",
    "    prem_cross = self.apply_cross_attention(prem_self, hypo_self)  # (B, 2H)\n",
    "    hypo_cross = self.apply_cross_attention(hypo_self, prem_self)  # (B, 2H)\n",
    "\n",
    "    # Sentence Aggregation: combine premise and hypothesis as unified input for classifier\n",
    "    combined = torch.cat([prem_self, hypo_self], dim=1)       # (B, 4H)\n",
    "    combined = self.dropout_encoder(combined)            # apply dropout to combined premise-hypothesis representation\n",
    "\n",
    "    # Classification\n",
    "    logits = self.classifier(combined)                # (B, shared.num_classes)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diVN3tW6qmTL"
   },
   "source": [
    "### 4.2.2 Training (3+4 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQqFb5Csqv03"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "m1_vanilla_model = Vanilla_NLI_Model(shared).to(device)\n",
    "m1_dual_attn_model = DualAttn_NLI_Model(shared).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()      # combine LogSoftmax and NLLLoss\n",
    "\n",
    "vanilla_optimizer = optim.Adam(m1_vanilla_model.parameters(), lr=shared.learning_rate)\n",
    "dual_attn_optimizer = optim.Adam(m1_dual_attn_model.parameters(), lr=shared.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hdF7T0pBxU2",
    "outputId": "2199f405-cfd4-4764-fcf4-8983dd8b17b4"
   },
   "outputs": [],
   "source": [
    "m1_vanilla_train_losses = []\n",
    "m1_vanilla_val_losses = []\n",
    "\n",
    "for epoch in range(shared.total_epoch):\n",
    "  m1_vanilla_model.train()\n",
    "  train_loss = 0\n",
    "\n",
    "  # Training loop\n",
    "  for prem, hypo, label in train_loader:\n",
    "    prem, hypo, label = prem.to(device), hypo.to(device), label.to(device)\n",
    "\n",
    "    # Forward\n",
    "    logits = m1_vanilla_model(prem, hypo)\n",
    "    loss = criterion(logits, label)\n",
    "\n",
    "    # Backward and optimize\n",
    "    vanilla_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    vanilla_optimizer.step()\n",
    "\n",
    "    # Accumulate batch loss\n",
    "    train_loss += loss.item()\n",
    "\n",
    "  train_avg_loss = train_loss / len(train_loader)\n",
    "  m1_vanilla_train_losses.append(train_avg_loss)\n",
    "\n",
    "  # Validation\n",
    "  m1_vanilla_model.eval()\n",
    "  m2_val_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for prem, hypo, label in val_loader:\n",
    "      prem, hypo, label = prem.to(device), hypo.to(device), label.to(device)\n",
    "\n",
    "      # Forward\n",
    "      logits = m1_vanilla_model(prem, hypo)\n",
    "      loss = criterion(logits, label)\n",
    "\n",
    "      # Accumulate batch loss\n",
    "      m2_val_loss += loss.item()\n",
    "\n",
    "  val_avg_loss = m2_val_loss / len(val_loader)\n",
    "  m1_vanilla_val_losses.append(val_avg_loss)\n",
    "\n",
    "  print(f\"Vanilla Epoch: {epoch+1}/{shared.total_epoch}\\tTrain Loss: {train_avg_loss:.4f}\\tVal Loss: {val_avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxDhMUoyUdz2",
    "outputId": "6bc8251f-3dda-4ed7-ff00-e17f3e56f9d6"
   },
   "outputs": [],
   "source": [
    "m1_dual_attn_train_losses = []\n",
    "m1_dual_attn_val_losses = []\n",
    "\n",
    "for epoch in range(shared.total_epoch):\n",
    "  m1_dual_attn_model.train()\n",
    "  train_loss = 0\n",
    "\n",
    "  # Training loop\n",
    "  for prem, hypo, label in train_loader:\n",
    "    prem, hypo, label = prem.to(device), hypo.to(device), label.to(device)\n",
    "\n",
    "    # Forward\n",
    "    logits = m1_dual_attn_model(prem, hypo)\n",
    "    loss = criterion(logits, label)\n",
    "\n",
    "    # Backward and optimize\n",
    "    dual_attn_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    dual_attn_optimizer.step()\n",
    "\n",
    "    # Accumulate batch loss\n",
    "    train_loss += loss.item()\n",
    "\n",
    "  train_avg_loss = train_loss / len(train_loader)\n",
    "  m1_dual_attn_train_losses.append(train_avg_loss)\n",
    "\n",
    "  # Validation\n",
    "  m1_dual_attn_model.eval()\n",
    "  m2_val_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for prem, hypo, label in val_loader:\n",
    "      prem, hypo, label = prem.to(device), hypo.to(device), label.to(device)\n",
    "\n",
    "      # Forward\n",
    "      logits = m1_dual_attn_model(prem, hypo)\n",
    "      loss = criterion(logits, label)\n",
    "\n",
    "      # Accumulate batch loss\n",
    "      m2_val_loss += loss.item()\n",
    "\n",
    "  val_avg_loss = m2_val_loss / len(val_loader)\n",
    "  m1_dual_attn_val_losses.append(val_avg_loss)\n",
    "\n",
    "  print(f\"Dual-Attn Epoch: {epoch+1}/{shared.total_epoch}\\tTrain Loss: {train_avg_loss:.4f}\\tVal Loss: {val_avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPkVjEM4LNu-"
   },
   "source": [
    "### 4.2.3 Loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "hznRuf-PLKk9",
    "outputId": "a20c8599-8ffc-4c94-bf73-3304dab0394e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch = range(1, shared.total_epoch + 1)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "\n",
    "# Training Loss\n",
    "axes[0].plot(epoch, m1_vanilla_train_losses, color='blue', label='No Attn')\n",
    "axes[0].plot(epoch, m1_dual_attn_train_losses, color='orange', label='Dual-Attn')\n",
    "axes[0].set_title('Training Loss per Epoch')\n",
    "axes[0].set_xticks(epoch)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Average Loss')\n",
    "axes[0].grid(axis='y')\n",
    "axes[0].legend()\n",
    "\n",
    "# Validation Loss\n",
    "axes[1].plot(epoch, m1_vanilla_val_losses, color='blue', label='No Attn')\n",
    "axes[1].plot(epoch, m1_dual_attn_val_losses, color='orange', label='Dual-Attn')\n",
    "axes[1].set_title('Validation Loss per Epoch')\n",
    "axes[1].set_xticks(epoch)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Average Loss')\n",
    "axes[1].grid(axis='y')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6SluyYhgRZi"
   },
   "source": [
    "### 4.2.4 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmt15RgAgS56",
    "outputId": "c2f1b704-72e3-4bd1-80d9-d525bfb18103"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Testing\n",
    "\n",
    "def evaluate_accuracy(model, test_loader, device, name):\n",
    "  model.eval()\n",
    "  preds, labels = [], []\n",
    "  with torch.no_grad():\n",
    "    for prem, hypo, label in test_loader:\n",
    "      prem, hypo, label = prem.to(device), hypo.to(device), label.to(device)\n",
    "      logits = model(prem, hypo)\n",
    "      pred = torch.argmax(logits, dim=1)\n",
    "      preds.extend(pred.cpu().numpy())\n",
    "      labels.extend(label.cpu().numpy())\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  print(f\"{name} Test Accuracy: {acc:.4f}\")\n",
    "  return acc, preds, labels\n",
    "\n",
    "m1_vanilla_acc, m1_vanilla_preds, m1_vanilla_labels = evaluate_accuracy(m1_vanilla_model, test_loader, device, name=\"Vanilla\")\n",
    "m1_dual_attn_acc, m1_dual_attn_preds, m1_dual_attn_labels = evaluate_accuracy(m1_dual_attn_model, test_loader, device, name=\"Dual-Attn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZW59q0hc0ZK"
   },
   "source": [
    "### 4.2.5 Classification Matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "id": "7pUh6VFOc7Tv",
    "outputId": "38d6cc75-b5c1-42ca-df9a-3f012287741c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Classification matrices\n",
    "print(\"================== Vanilla BiLSTM NLI ==================\")\n",
    "print(classification_report(m1_vanilla_labels, m1_vanilla_preds, target_names=list(shared.label_mapping.keys())))\n",
    "\n",
    "print(\"\\n================= Dual-Attn BiLSTM NLI =================\")\n",
    "print(classification_report(m1_dual_attn_labels, m1_dual_attn_preds, target_names=list(shared.label_mapping.keys())))\n",
    "\n",
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "cm_vanilla = confusion_matrix(m1_vanilla_labels, m1_vanilla_preds)\n",
    "disp_vanilla = ConfusionMatrixDisplay(confusion_matrix=cm_vanilla, display_labels=list(shared.label_mapping.keys()))\n",
    "disp_vanilla.plot(cmap=\"Blues\", ax=axes[0], colorbar=False)\n",
    "axes[0].set_title(\"Vanilla Confusion Matrix\")\n",
    "\n",
    "cm_dual = confusion_matrix(m1_dual_attn_labels, m1_dual_attn_preds)\n",
    "disp_dual = ConfusionMatrixDisplay(confusion_matrix=cm_dual, display_labels=list(shared.label_mapping.keys()))\n",
    "disp_dual.plot(cmap=\"Blues\", ax=axes[1], colorbar=False)\n",
    "axes[1].set_title(\"Dual-Attn Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMb7H46HOLqG"
   },
   "source": [
    "### 4.2.6 Evaluation\n",
    "\n",
    "In summary, the model struggles to predict OOV words, regardless of how much content it has learned from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hVAggi_P469"
   },
   "source": [
    "#### Training Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QWsqzGoSlMm"
   },
   "source": [
    "The training loss of both models shows a similar trends that decreases rapidly and stabilizes around epoch 10, indicating that the model successfully fits the training data.\n",
    "\n",
    "The train loss of the model with dual-attention often more stable than the one without attention.\n",
    "\n",
    "The consistent convergence pattern suggests that thiese vanilla NLI classicier models are capable of capturing the sequence patterns within the training distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YABoXw1mLYfT"
   },
   "source": [
    "#### Validation Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cc59zJh0Siqz"
   },
   "source": [
    "The validation loss rises steadily throughout training, revealing a clear sign of overfitting.\n",
    "\n",
    "This outcome is expected. Since the word-to-index vocabulary was intentionally built only from the training set\n",
    "\n",
    "As a result, unseen or rare tokens are replaced by the \\<UNK> tag, leading to higher loss and reduced generalization capability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyeDvmtulWpr"
   },
   "source": [
    "#### Classification Matrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZZo9H5Drfs4"
   },
   "source": [
    "The dual-attention mechanism does not notably improve overall accuracy, but enhances the prediction of the **true positive** label \"entails\". This is likely due to label imbalance in training set:\n",
    "\n",
    "Two-thirds of the training data are \"neutral\", while the validation and test sets are balanced. This make the vanilla model to underperform on \"entails\" examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhSE5ON4_r0C"
   },
   "source": [
    "## 4.3 Model 2: Bi-LSTM + Attention NLI Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBxtLuj6IgKV"
   },
   "source": [
    "### 4.3.1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b14s1AoN_wNC"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# NLI BiLSTM with Attention (Classifier + Training Loop)\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "class NLI_BiLSTM_Attention(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.bilstm = nn.LSTM(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.attn = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 8, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def attention_pool(self, lstm_out):\n",
    "        attn_weights = F.softmax(self.attn(lstm_out), dim=1)  # [batch, seq_len, 1]\n",
    "        context = torch.sum(attn_weights * lstm_out, dim=1)   # [batch, hidden_dim*2]\n",
    "        return context\n",
    "\n",
    "    def forward(self, premise, hypothesis):\n",
    "        # Encode premise\n",
    "        prem_embed = self.embedding(premise)\n",
    "        prem_out, _ = self.bilstm(prem_embed)\n",
    "        prem_vec = self.attention_pool(prem_out)\n",
    "\n",
    "        # Encode hypothesis\n",
    "        hyp_embed = self.embedding(hypothesis)\n",
    "        hyp_out, _ = self.bilstm(hyp_embed)\n",
    "        hyp_vec = self.attention_pool(hyp_out)\n",
    "\n",
    "        # Combine\n",
    "        combined = torch.cat([\n",
    "            prem_vec,\n",
    "            hyp_vec,\n",
    "            torch.abs(prem_vec - hyp_vec),\n",
    "            prem_vec * hyp_vec\n",
    "        ], dim=1)\n",
    "\n",
    "        logits = self.fc(combined)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VD1M_6L7Iy1b"
   },
   "source": [
    "### 4.3.2 Training (4 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7FBxqJVgEjVw",
    "outputId": "36205daa-9c0a-4356-fd17-13d7cfd0fdd3"
   },
   "outputs": [],
   "source": [
    "# Assuming label_mapping and shared are already defined\n",
    "# Define the number of classes from the label_mapping\n",
    "\n",
    "model_2 = NLI_BiLSTM_Attention(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=shared.embed_dim,\n",
    "    hidden_dim=shared.hidden_dim,\n",
    "    num_classes=shared.num_classes,\n",
    "    pad_idx=shared.pad_idx\n",
    ").to(device)\n",
    "\n",
    "m2_criterion = nn.CrossEntropyLoss()\n",
    "m2_optimizer = torch.optim.Adam(model_2.parameters(), lr=shared.learning_rate)\n",
    "\n",
    "m2_train_losses, m2_val_losses = [], []\n",
    "\n",
    "for epoch in range(shared.total_epoch):\n",
    "    # ---------- TRAIN ----------\n",
    "    model_2.train()\n",
    "    running_loss, preds, labels_all = 0, [], []\n",
    "    for premise, hypothesis_in, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{shared.total_epoch}\"):\n",
    "        premise, hypothesis_in, labels = premise.to(device), hypothesis_in.to(device), labels.to(device)\n",
    "        m2_optimizer.zero_grad()\n",
    "        outputs = model_2(premise, hypothesis_in)\n",
    "        loss = m2_criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        m2_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "        labels_all.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(labels_all, preds)\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    m2_train_losses.append(train_loss)\n",
    "\n",
    "    # ---------- VALIDATION ----------\n",
    "    model_2.eval()\n",
    "    m2_val_loss, m2_val_preds, m2_val_labels = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for premise, hypothesis_in, labels in val_loader:\n",
    "            premise, hypothesis_in, labels = premise.to(device), hypothesis_in.to(device), labels.to(device)\n",
    "            outputs = model_2(premise, hypothesis_in)\n",
    "            loss = m2_criterion(outputs, labels)\n",
    "            m2_val_loss += loss.item()\n",
    "            m2_val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            m2_val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(m2_val_labels, m2_val_preds)\n",
    "    m2_val_loss /= len(val_loader)\n",
    "    m2_val_losses.append(m2_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={m2_val_loss:.4f}, Train Acc={train_acc:.3f}, Val Acc={val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nr9KNsCIbpq"
   },
   "source": [
    "### 4.3.3 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xqOzcdGUEmhM",
    "outputId": "fa8d18a2-9cc9-456e-b1ba-32d2b7074e83"
   },
   "outputs": [],
   "source": [
    "# Final evaluation metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(m2_val_labels, m2_val_preds, target_names=list(shared.label_mapping.keys())))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(m2_val_labels, m2_val_preds)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(shared.label_mapping.keys())).plot(cmap='Blues')\n",
    "plt.title(\"Validation Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Loss Curves\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(m2_train_losses, label=\"Train Loss\", marker='o')\n",
    "plt.plot(m2_val_losses, label=\"Val Loss\", marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4w_n2P2_xxm"
   },
   "source": [
    "## 4.4 Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpZNRYhe_1ae"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
